# 7. Clustering

Once we have normalized the data and removed confounders we can carry out analyses that are relevant to the biological questions at hand. The exact nature of the analysis depends on the data set. One of the most promising applications of scRNA-seq is de novo discovery and annotation of cell-types based on transcription profiles. This requires the identification of groups of cells based on the similarities of the transcriptomes without any prior knowledge of the label a.k.a. unsupervised clustering. To avoid the challenges caused by the noise and high dimensionality of the scRNA-seq data, clustering is performed after feature selection and dimensionality reduction. For data that has not required batch correction this would usually be based on the PCA output. As our data has required batch correction we will use the “corrected” reducedDims data.

We will focus here on graph-based clustering, however, it is also possible to apply hierarchical clustering and k-means clustering on smaller data sets


!!! r-project-2 "We will use the data set generated in the previous session. This contains 7 samples from the Caron data set. For the purposes of these materials, in the interests of time, each sample has been downsampled to only contain 500 cells."

    ```r
    library(scater)
    library(scran)
    library(bluster)
    library(cluster)
    library(igraph)
    library(pheatmap)
    library(patchwork)
    library(tidyverse)
    ```
    ```r
    sce <- readRDS("R_objects/Caron_batch_corrected.500.rds")
    ```
    ```r
    table(sce$SampleName)
    ```

## Introduction to Graph-based clustering

Graph-based clustering entails building a nearest-neighbour (NN) graph using cells as nodes and their similarity as edges, then identifying ‘communities’ of cells within the network. A graph-based clustering method has three key parameters:

- How many neighbors are considered when constructing the graph
- What scheme is used to weight the edges
- Which community detection algorithm is used to define the clusters

### Connecting nodes (cells) based on nearest neighbours
Two types of NN graph may be used: “K nearest-neighbour” (KNN) and “shared nearest-neighbour” (SNN). In a KNN graph, two nodes (cells), say A and B, are connected by an edge if the distance between them is amongst the k smallest distances from A to other cells. In an SNN graph A and B are connected if the distance is amongst the k samllest distances from A to other cells and also among the k smallest distance from B to other cells.

<center>![image](../r_images/nodebased-nearest-1.png){width="300"}</center>

In the figure above, if k is 5, then A and B would be connected in a KNN graph as B is one of the 5 closest cells to A, however, they would not be connected in an SNN graph as B has 5 other cells that are closer to it than A.

The value of k can be roughly interpreted as the anticipated size of the smallest subpopulation” (see `scran`’s `buildSNNGraph()` [manual](https://rdrr.io/bioc/scran/man/buildSNNGraph.html)).

The plot below shows the same data set as a network built using three different numbers of neighbours: 5, 15 and 25 (from [here](https://biocellgen-public.svi.edu.au/mig_2019_scrnaseq-workshop/clustering-and-cell-annotation.html#example-1.-graph-based-clustering-deng-dataset)).

<center>![image](../r_images/nodebased-nearest-2.png){width="600"}</center>

### Weighting the edges
The edges between nodes (cells) can be weighted based on the similarity of the cells; edges connecting cells that are more closely related will have a higher weight. The three common methods for this weighting are (see the bluster package documentation for the makeSNNGraph function):

- rank - the weight is based on the highest rank of the shared nearest neighbours
- number - the weight is based the number of nearest neighbours in common between the two cells
- jaccard - the [Jaccard index](https://en.wikipedia.org/wiki/Jaccard_index) of the two cells’ sets of nearest neighbours.

### Grouping nodes (cells) into clusters
Clusters are identified using an algorithm that interprets the connections of the graph to find groups of highly interconnected cells. A variety of different algorithms are available to do this, in these materials we will focus on three methods: walktrap, louvain and leiden. See the OSCA book for details of others available in scran.

### Modularity
Several methods to detect clusters (‘communities’) in networks rely on a metric called “modularity”. For a given partition of cells into clusters, modularity measures how separated clusters are from each other, based on the difference between the observed and expected weight of edges between nodes. For the whole graph, the closer to 1 the better.

### Pros and Cons of graph based clustering

- Pros:
    - fast and memory efficient (avoids the need to construct a distance matrix for all pairs of cells)
    - no assumptions on the shape of the clusters or the distribution of cells within each cluster
    - no need to specify a number of clusters to identify (but the size of the neighbourhood used affects the size of clusters)

- Cons:
    - loss of information beyond neighboring cells, which can affect community detection in regions with many cells.

## Implementation

The implementation of clustering in R is carried out using functions from a number of different packages, in particular the bluster and igraph packages. scran provides a handy “wrapper” function `clusterCells` that allows us use a variety of different algorithms with one simple command.

By default `clusterCells` just returns a vector containing the cluster number for each cell. We can also retrieve the intermediate statistics (varying according to the algorithm used) and the SNN graph by specifying the bluster argument `full = TRUE`. If you are only interested in retrieving the clusters, this isn’t necessary but in this first instance we will retrieve the graph and visualise it. The default algorithm for clusterCells is Walktrap with k is set to 10 by default. The default edge weighting is “rank”.

!!! r-project "code"

    ```r
    clustering1 <- clusterCells(sce, use.dimred="corrected", full=TRUE)
    This has defined 24 clusters with varying numbers of cells:
    ```
    ```r
    table(clustering1$clusters)
    ```
    
    The number of cells in the data set is large and plotting all the cells would take too long, so we randomly choose 1000 nodes (cells) in the network before plotting the resulting smaller network. Adding sample data to the graph and plotting the results are done using the igraph package. Cells can be color-coded by sample type:
    
    ```r
    # extract the graph
    snn.gr <- clustering1$objects$graph
    
    # Add Sample group to vertices (nodes, ie cells)
    V(snn.gr)$SampleGroup <- as.character(colData(sce)$SampleGroup)
    
    # pick 1000 nodes randomly
    set.seed(1423)
    selectedNodes <- sample(3500, 1000)
    
    # subset graph for these 1000 randomly chosen nodes
    snn.gr.subset <- subgraph(snn.gr, selectedNodes)
    
    # set colors for clusters
    grps <-  V(snn.gr.subset)$SampleGroup
    cols <- c("dodgerblue", "lightyellow")[as.numeric(factor(grps))]
    names(cols) <- grps
    
    # plot graph
    plot.igraph(snn.gr.subset,
      layout = layout_with_fr(snn.gr.subset),
      vertex.size = 3, 
      vertex.label = NA,
      vertex.color = cols,
      frame.color = cols,
      main = "default parameters"
    )
    
    # add legend
    legend('bottomright',
           legend=unique(names(cols)),
           pch=21,
           pt.bg=unique(cols),
           pt.cex=1, cex=.6, bty="n", ncol=1)
    ```
    ![image](../r_images/55-clustering-defaultparameters.png)
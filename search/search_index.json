{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>"},{"location":"#analysis-of-single-cell-rna-seq-data","title":"Analysis of single cell RNA-seq data","text":"<p>Episodes</p> <ol> <li>Alignment and feature counting with Cell Ranger</li> <li>QC and Exploratory Analysis</li> <li>Normalisation</li> <li>sctransform: Variance Stabilising Transformation</li> <li>Feature Selection and Dimensionality Reduction</li> <li>Batch correction and data set integration</li> <li>Clustering</li> <li>Identification of cluster marker genes</li> <li>Differential expression analysis</li> <li> Differential Abundance</li> </ol> <p>Prerequisites</p> <ul> <li> Inermediate level knowledge on R (programming language)</li> <li> Familiarity with terminal and basic linux commands</li> <li> Some knowledge on shell environment variables and <code>for</code> loops</li> <li> Ability to use a terminal based text editor such as <code>nano</code> <ul> <li> This is not much of an issue as we are using JupyterHub which has a more friendlier text editor.   </li> </ul> </li> <li> Intermediate level knowledge on Molecular Biology and Genetics</li> </ul> <p>Recommended but not required</p> <ul> <li> Attend Genomics Data Carpentry,  RNA-Seq Data Analysis, Introduction to R and/or Intermediate R</li> </ul> <p></p> <p>Data set</p> <ul> <li>Data used in this workshop is based on CaronBourque2020 relating to pediatric leukemia, with four sample types, including:<ul> <li>pediatric Bone Marrow Mononuclear Cells (PBMMCs)</li> <li>three tumour types: ETV6-RUNX1, HHD, PRE-T</li> </ul> </li> </ul> <p>Attribution notice</p> <ul> <li> <p>Material used in this workshop is based on folloowing repositories</p> <ul> <li>Introduction to single-cell RNA-seq data analysis - University of Cambridge https://bioinformatics-core-shared-training.github.io/SingleCell_RNASeq_Jan23/</li> <li>Analysis of single cell RNA-seq data - Welcome Sanger Institute https://www.singlecellcourse.org/</li> </ul> </li> </ul> <p>References</p> <ul> <li>https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-0947-7</li> <li>https://www.nature.com/articles/nbt.4091</li> <li>https://arxiv.org/abs/physics/0512106</li> <li>https://www.nature.com/articles/s41598-019-41695-z</li> <li>https://www.nature.com/articles/s41598-019-41695-z#Fig3</li> </ul>"},{"location":"episodes/0/","title":"Workflow","text":"<p> <pre><code>flowchart TD\n    id1[\"Sequencing QC\"] --&gt; id2[\"Read alignment, Feature Counting, Cell calling\"] --&gt; id3[\"QC\"] --&gt; id4[\"Count normalisation\"] --&gt; id5[\"Feature selection\"] --&gt; id6[\"Dimensionality reduction\"] --&gt; id7[\"Data set integration\"] --&gt; id8[\"Clustering\"] --&gt; id9[\"Cluster marker genes\"] --&gt; id10[\"DE between conditions\"] --&gt; id11[\"Differential abundance between conditions\"]</code></pre> </p>"},{"location":"episodes/1/","title":"1. Alignment and feature counting with Cell Ranger","text":"<p>The first step in the analysis of single cell RNAseq data is to align the sequenced reads against a genomic reference and then use a transcriptome annotation to generate read counts for each feature of interest. Typically for scRNAseq the features of interest are genes. </p> <p>Due to time constraints, this will not be covered in today's workshop. We will begin this workshop with the filtered feature count output files generated by the Cell Ranger count function. </p> <p>All the information relating to alignment and feature counting is contained below for you to read in your own time.</p> Indexing the reference genome and running CellRanger count <p>There are a variety of tools for doing alighment and feature counting and your choice will depend in part on the method by which the library was generated. For data generated using the 10x-Chromium method data the most common approach is to use the Cell Ranger tool provided by 10x. This not only carries out the alignment and feature counting, but will also:</p> <ul> <li>Call cells, i.e. filter the raw matrix to remove droplets that do not contain cells</li> <li>Generate a very useful report in html format, which will provide some QC metrics and an initial look at the data</li> <li>Generate a \u201ccloupe\u201d file, which can be opened using the 10x Loupe Browser software to further explore the data.</li> </ul> <p>Cell Ranger is computationally very intensive, you will not be able to run it on a laptop or standard desktop computer. You will need access to, for example, a high performance computing (HPC) cluster, a server or other cloud-based computational resource with sufficient power - talk to your local IT support.</p> <p>Alternative methods include:</p> <ul> <li>STAR solo - this tool is built into the general purpose STAR aligner (Cell Ranger actually uses STAR under the hood). This will generate outputs very similar to Cell Ranger minus the cloupe file and the QC report. The advantage over Cell Ranger is that it is much less computationally intensive and will run with lower memory requirements in a shorter time.</li> <li>Alevin - This tool is based on the popular Salmon tool for bulk RNAseq feature counting. Alevin supports both 10x-Chromium and Drop-seq derived data.</li> </ul> <p>For the purposes of this course, seeing as we are working with 10x-Chromium derived data, we will use Cell Ranger. As detailed instructions are available on the Cell Ranger pages of the 10x website, this chapter will not be comprehensive in terms of all options, but should provide a brief overview.</p>"},{"location":"episodes/1/#index-the-reference-genome","title":"Index the reference genome","text":"<p>To index our genome, we can use the cellranger mkref tool with the following arguments (replacing {...} with the relevant piece of information):</p> <p><pre><code>cellranger mkref \\\n  --fasta={GENOME FASTA} \\\n  --genes={ANNOTATION GTF} \\\n  --genome={OUTPUT FOLDER FOR INDEX} \\\n  --nthreads={CPUS}\n</code></pre> where:</p> <ul> <li><code>GENOME FASTA</code> is a file containing the reference genome in FASTA format.</li> <li><code>ANNOTATION GTF</code> is a file containing the transcript annotation file in GTF format.</li> <li><code>OUTPUT FOLDER FOR INDEX</code>is a name for the output folder containing the new reference package (you do not need to create this folder).</li> <li><code>CPUS</code> - Is the number of CPUs we would like CellRanger to use. The more CPUs CellRanger can use, the faster the job (up to a point).</li> </ul> <p>code</p> <pre><code>cd Data/references\n\nmodule purge &amp;&amp; module load CellRanger/7.1.0\n\ncellranger mkref \\\n  --fasta=Homo_sapiens.GRCh38.dna.chromosome.21.fa \\\n  --genes=gencode.v41.primary_assembly.annotation.chr21.gtf \\\n  --genome=cellranger_index \\\n  --nthreads 4\n</code></pre> output <pre><code>['/scale_wlg_persistent/filesets/opt_nesi/CS400_centos7_bdw/CellRanger/7.1.0/bin/rna/mkref', '--fasta=Homo_sapiens.GRCh38.dna.chromosome.21.fa', '--genes=gencode.v41.primary_assembly.annotation.chr21.gtf', '--genome=cellranger_index', '--nthreads=7']\nCreating new reference folder at /scale_wlg_persistent/filesets/project/nesi02659/sc-rna/Data/references/cellranger_index\n...done\n\nWriting genome FASTA file into reference folder...\n...done\n\nIndexing genome FASTA file...\n...done\n\nWriting genes GTF file into reference folder...\n...done\n\nGenerating STAR genome index (may take over 8 core hours for a 3Gb genome)...\nAug 05 19:27:22 ..... started STAR run\nAug 05 19:27:22 ... starting to generate Genome files\nAug 05 19:27:23 ... starting to sort Suffix Array. This may take a long time...\nAug 05 19:27:24 ... sorting Suffix Array chunks and saving them to disk...\nAug 05 19:27:52 ... loading chunks from disk, packing SA...\nAug 05 19:27:53 ... finished generating suffix array\nAug 05 19:27:53 ... generating Suffix Array index\nAug 05 19:27:55 ... completed Suffix Array index\nAug 05 19:27:55 ..... processing annotations GTF\nAug 05 19:27:55 ..... inserting junctions into the genome indices\nAug 05 19:27:58 ... writing Genome to disk ...\nAug 05 19:27:58 ... writing Suffix Array to disk ...\nAug 05 19:27:58 ... writing SAindex to disk\nAug 05 19:27:58 ..... finished successfully\n...done.\n\nWriting genome metadata JSON file into reference folder...\nComputing hash of genome FASTA file...\n...done\n\nComputing hash of genes GTF file...\n...done\n\n...done\n\n&gt;&gt;&gt; Reference successfully created! &lt;&lt;&lt;\n\nYou can now specify this reference on the command line:\ncellranger --transcriptome=/scale_wlg_persistent/filesets/project/nesi02659/sc-rna/Data/references/cellranger_index ...\n</code></pre>"},{"location":"episodes/1/#cell-ranger-count","title":"Cell Ranger <code>count</code>","text":""},{"location":"episodes/1/#preparing-the-raw-fastq-files","title":"Preparing the raw fastq files","text":"<p>To run the Cell Ranger count function, the fastq files for all samples to be processed should be placed in a single directory. Cell Ranger will be run separately on each sample. You will need to provide the software with the name of the sample to be processed (e.g. SRR9264343). Cell Ranger expects the file names of the fastq files to follow a specific convention so that it can correctly identify the files for the specific sample. If the files names of your fastqs do not match this convention you will need to rename them.</p> <p>The convention is the default convention used by <code>bcl2fastq</code> (the tool that converts the raw sequencing data in <code>bcl</code> format into <code>fastq</code> files):</p> <pre><code>&lt;SampleName&gt;_S&lt;SampleNumber&gt;_L00&lt;Lane&gt;_&lt;Read&gt;_001.fastq.gz\n</code></pre> <ul> <li><code>&lt;SampleName&gt;</code> - An identifier for the sample, this is what Cell Ranger uses to determine which fastq files to combine into a single sample.</li> <li><code>&lt;SampleNumber&gt;</code> - This is the sample number based on the order that samples were listed in the sample sheet used when running bcl2fastq. This is not important for Cell Ranger, other than it indicates the end of the Sample Name, you can set all your samples to S1.</li> <li><code>&lt;Lane&gt;</code> - The lane number. If your sequencing was run across multiple lanes, then you may have multiple sets of fastqs for a single sample with different lane numbers.</li> <li><code>&lt;Read&gt;</code> - The read type: R1 for Read 1, R2 for Read 2, and index reads are I1 and I2. 001 - The last segment is always 001.</li> </ul> <p>e.g. for a single sample in the Caron data set we have:</p> <pre><code>    SRR9264343_S0_L001_I1_001.fastq.gz\n    SRR9264343_S0_L001_R1_001.fastq.gz\n    SRR9264343_S0_L001_R2_001.fastq.gz\n</code></pre>"},{"location":"episodes/1/#running-cellranger-count-note-this-takes-time-","title":"Running <code>cellranger count</code> ( NOTE: this takes time ---)","text":"<p>The minimum information require to run cellranger count is:</p> <ul> <li><code>--id</code> - A sample ID. This is used for naming the outputs</li> <li><code>--transcriptome</code>- the directory containing the Cell Ranger reference</li> <li> <p><code>--fastqs</code> - the directory containing the fastq files This will process all fastq files in the --fastqs directory into a single sample. If you have multiple samples in a single directory then you need to add:</p> </li> <li> <p><code>--sample</code> - the SampleName from the fastq files as above. In addition, Cell Ranger is very computationally intensive, you will usually be wanting to run it on a high performance cluster or server. It will greedily attempt to use all resources it can find available, and so it is advisable to set limits to the resources it will use:</p> </li> <li> <p><code>--localcores</code> - the number of processors Cell Ranger should use</p> </li> <li><code>--localmem</code> - the amount of memory, in Gigabytes, Cell Ranger should use.</li> </ul> <p>A complete command for processing on of the Caron samples might be:</p> <pre><code>cellranger count --id={OUTPUT_SAMPLE_NAME} \\\n                 --transcriptome={DIRECTORY_WITH_REFERENCE} \\\n                 --fastqs={DIRECTORY_WITH_FASTQ_FILES} \\\n                 --sample={NAME_OF_SAMPLE_IN_FASTQ_FILES} \\\n                 --localcores={NUMBER_OF_CPUS} \\\n                 --localmem={RAM_MEMORY}\n</code></pre> <p>code</p> <pre><code>cellranger count \\\n  --id=ETV6_RUNX1_rep1 \\\n   --transcriptome=Data/references/cellranger_index \\\n   --fastqs=Data/fastq/ \\\n   --sample=SRR9264343 \\\n   --localcores=8 \\\n   --localmem=24\n</code></pre> Slurm-script - This will run for about 9 minutes <pre><code>#!/bin/bash -e \n\n#SBATCH --account nesi02659\n#SBATCH --job-name cell-ranger-count\n#SBATCH --cpus-per-task 16\n#SBATCH --mem 24G\n#SBATCH --time 00:20:00 \n#SBATCH --output slurmlog/%j.out\n\nmodule purge\nmodule load CellRanger/7.1.0\n\ncellranger count \\\n            --id=ETV6_RUNX1_rep1 \\\n            --transcriptome=Data/references/cellranger_index \\\n            --fastqs=Data/fastq/ \\\n            --sample=SRR9264343 \\\n            --localcores=${SLURM_CPUS_PER_TASK} \\\n            --localmem=22\n</code></pre> <code>ls -F ETV6_RUNX1_rep1/outs/</code> <pre><code>analysis/                    filtered_feature_bc_matrix.h5  possorted_genome_bam.bam      raw_feature_bc_matrix.h5\ncloupe.cloupe                metrics_summary.csv            possorted_genome_bam.bam.bai  web_summary.html\nfiltered_feature_bc_matrix/  molecule_info.h5               raw_feature_bc_matrix/\n</code></pre>"},{"location":"episodes/2/","title":"2. QC and Exploratory Analysis","text":"<p>Retrieve pre-made R code Open Terminal tab in RStudio and run:</p> <p>code</p> <pre><code>wget -c https://github.com/GenomicsAotearoa/scRNA-seq-data-analysis/releases/download/2024-Apr/Scripts.zip\n\nunzip Scripts.zip\n</code></pre> <p>code</p> <pre><code>library(DropletUtils)\nlibrary(scater)\nlibrary(ensembldb)\nlibrary(AnnotationHub)\nlibrary(BiocParallel)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(ggvenn)\n</code></pre> <p>code</p> <pre><code>samplesheet &lt;- read.table(\"Data/sample_sheet.tsv\", sep='\\t', header=TRUE)\n</code></pre> <ul> <li>Here we are selecting to use forked processes with MulticoreParam and instructing the function to use 4 cores. </li> </ul> <p><pre><code>bp.params &lt;- MulticoreParam(workers = 4)\n</code></pre> <pre><code>sample.path &lt;- \"Data/CellRanger_Outputs/SRR9264343/outs/filtered_feature_bc_matrix/\"\nsce.sing &lt;- read10xCounts(sample.path, col.names=TRUE, BPPARAM = bp.params)\nsce.sing\n</code></pre></p> Output <pre><code>class: SingleCellExperiment \ndim: 37764 3153 \nmetadata(1): Samples\nassays(1): counts\nrownames(37764): ENSG00000243485 ENSG00000237613 ...\n  ENSG00000278817 ENSG00000277196\nrowData names(3): ID Symbol Type\ncolnames(3153): AAACCTGAGACTTTCG-1 AAACCTGGTCTTCAAG-1 ...\n  TTTGTCACAGGCTCAC-1 TTTGTCAGTTCGGCAC-1\ncolData names(2): Sample Barcode\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\n</code></pre>"},{"location":"episodes/2/#the-singlecellexperiment-object","title":"The SingleCellExperiment object","text":"<p>The data have been loaded as a SingleCellExperiment object. The details of the structure of the object are described here. In summary, it stores various data types in a single object. Currently it will contain:</p> <ul> <li>the count matrix</li> <li>feature (gene) metadata</li> <li>cell (droplet) metadata</li> </ul> <p>Later we will also add the outcomes of downstream analysis such as normalisation and dimensionality reduction.</p> <p></p>"},{"location":"episodes/2/#the-counts-matrix","title":"The counts matrix","text":"<p>Compared to bulk RNA-seq, Single-cell RNA-seq data is sparse, i.e., there are many missing values or zeroes. This is particularly true with droplet-based methods such as 10X, mostly because:</p> <ul> <li>any given cell does not express each gene</li> <li>the library preparation does not capture all transcripts the cell was expressing</li> <li>the sequencing depth per cell is relatively low and not all expressed genes are detected</li> </ul> <p>We can access the counts matrix with the counts function. Given the large number of droplets in a sample, count matrices can be large.</p> <p>code</p> <pre><code>dim(counts(sce.sing))\n</code></pre> <ul> <li>They are however very sparse, that is, most of the entries are 0\u2019s. To save memory the counts can be stored in a \u2018sparse matrix\u2019 that only stores non-zero values, in this case as a dgCMatrix object. <pre><code>counts(sce.sing)[1:10, 1:10]\n</code></pre></li> </ul> Output <pre><code>10 x 10 sparse Matrix of class \"dgCMatrix\"\n  [[ suppressing 10 column names 'AAACCTGAGACTTTCG-1', 'AAACCTGGTCTTCAAG-1', 'AAACCTGGTGCAACTT-1' ... ]]\n\nENSG00000243485 . . . . . . . . . .\nENSG00000237613 . . . . . . . . . .\nENSG00000186092 . . . . . . . . . .\nENSG00000238009 . . . . . . . . . .\nENSG00000239945 . . . . . . . . . .\nENSG00000239906 . . . . . . . . . .\nENSG00000241860 . . . . . . . . . .\nENSG00000241599 . . . . . . . . . .\nENSG00000286448 . . . . . . . . . .\nENSG00000236601 . . . . . . . . . .\n</code></pre>"},{"location":"episodes/2/#features","title":"Features","text":"<p>Details about the \u201cfeatures\u201d (in this case genes) can by accessed using the rowData function. Currently it contains the ensembl gene ID and the gene symbol, which have been derived from the 10x reference used by CellRanger. It also contains a \u201cType\u201d column, which tells us what sort of data we are looking at; in this case it is \u201cGene Expression\u201d. If we wish to, we can add further annotation to the features by adding extra columns to this data frame.</p> <p>code</p> <pre><code>rowData(sce.sing)\n</code></pre> Output - The rows of this table correspond to the rows of the count matrix; the row names of this table will match the row names of the counts matrix - currently these are the Ensembl IDS: <pre><code>DataFrame with 37764 rows and 3 columns\n                             ID          Symbol            Type\n                    &lt;character&gt;     &lt;character&gt;     &lt;character&gt;\nENSG00000243485 ENSG00000243485     MIR1302-2HG Gene Expression\nENSG00000237613 ENSG00000237613         FAM138A Gene Expression\nENSG00000186092 ENSG00000186092           OR4F5 Gene Expression\nENSG00000238009 ENSG00000238009 ENSG00000238009 Gene Expression\nENSG00000239945 ENSG00000239945 ENSG00000239945 Gene Expression\n...                         ...             ...             ...\nENSG00000277836 ENSG00000277836 ENSG00000277836 Gene Expression\nENSG00000278633 ENSG00000278633 ENSG00000278633 Gene Expression\nENSG00000276017 ENSG00000276017 ENSG00000276017 Gene Expression\nENSG00000278817 ENSG00000278817 ENSG00000278817 Gene Expression\nENSG00000277196 ENSG00000277196 ENSG00000277196 Gene Expression\n</code></pre> <pre><code>rownames(counts(sce.sing))[1:6]\n</code></pre>"},{"location":"episodes/2/#droplet-annotation","title":"Droplet annotation","text":"<p>code</p> <pre><code>colData(sce.sing)\ncolnames(counts(sce.sing))[1:6]\n</code></pre>"},{"location":"episodes/2/#properties-of-scrna-seq-data","title":"Properties of scRNA-seq data","text":""},{"location":"episodes/2/#number-of-genes-detected-per-cell","title":"Number of genes detected per cell","text":"<p>The number and identity of genes detected in a cell varies greatly across cells: the total number of genes detected across all cells is far larger than the number of genes detected in each cell.</p> <p>For the current set of samples the total number of genes detected across cells was 26468 out of 37764 gene in the reference, but if we look at the number of genes detected in each cell, we can see that this ranges from 40 to 5547, with a median of 2562.</p> <p>code</p> <p><pre><code>genesPerCell &lt;- colSums(counts(sce.sing) &gt; 0)\nplot(density(genesPerCell), main=\"\", xlab=\"Genes per cell\")\n</code></pre> </p>"},{"location":"episodes/2/#total-umi-for-a-gene-versus-the-number-of-times-detected","title":"Total UMI for a gene versus the number of times detected","text":"<p>If we compare the number of UMI\u2019s assigned to an individual gene to the number of cells in which that gene is detected, we can see that highly expressed genes tend to be detected in a higher proportion of cells than lowly expressed genes. Remember that due to low sequencing depth, not all expressed genes are detected in a cell.</p> <p>code</p> <p><pre><code>plot(rowSums(counts(sce.sing)) / rowSums(counts(sce.sing) &gt; 0),\n     rowMeans(counts(sce.sing) &gt; 0),\n     log = \"x\",\n     xlab=\"Mean UMIs per cell\",\n     ylab=\"proportion of cells expressing the gene\"\n)\n</code></pre> </p>"},{"location":"episodes/2/#distribution-of-counts-for-a-gene-across-cells","title":"Distribution of counts for a gene across cells","text":"<p>We could also look at the distribution of counts for individual genes across all cells. The plot below shows this distribution for the top 20 genes detected.</p> <p>code</p> <pre><code>rel_expression &lt;- t( t(counts(sce.sing)) / colSums(counts(sce.sing))) * 100\nrownames(rel_expression) &lt;- rowData(sce.sing)$Symbol\nmost_expressed &lt;- sort(rowSums( rel_expression ), decreasing = T)[20:1]\nplot_data &lt;- as.matrix(t(rel_expression[names(most_expressed),]))\n\nboxplot(plot_data, cex=0.1, las=1, xlab=\"% total count per cell\", horizontal=TRUE)\n</code></pre> Output <p></p>"},{"location":"episodes/2/#quality-control","title":"Quality Control","text":"info <p>The cell calling performed by CellRanger does not always retain only droplets containing cells. Poor-quality cells, or rather droplets, may be caused by cell damage during dissociation or failed library preparation. They usually have low UMI counts, few genes detected and/or high mitochondrial content. The presence of these droplets in the data set may affect normalisation, assessment of cell population heterogeneity, and clustering:</p> <ul> <li>Normalisation: Contaminating genes, \u2018the ambient RNA\u2019, are detected at low levels in all libraries. In low quality libraries with low RNA content, scaling will increase counts for these genes more than for better-quality cells, resulting in their apparent upregulation in these cells and increased variance overall.</li> <li>Cell population heterogeneity: variance estimation and dimensionality reduction with PCA where the first principal component will be correlated with library size, rather than biology.</li> <li>Clustering: higher mitochondrial and/or nuclear RNA content may cause low-quality cells to cluster separately or form states or trajectories between distinct cell types.</li> </ul> <p>In order to remove or reduce the impact of poor-quality droplets on our downstream analysis we will attempt to filter them out using some QC metrics. The three principle means of doing this are to apply thresholds for inclusion on three characteristics:</p> <ul> <li> <p>The library size defined as the total sum of UMI counts across all genes; cells with small library sizes are considered to be of low quality as the RNA has not been efficiently captured, i.e. converted into cDNA and amplified, during library preparation.</p> </li> <li> <p>The number of expressed genes in each cell defined as the number of genes with non-zero counts for that cell; any cell with very few expressed genes is likely to be of poor quality as the diverse transcript population has not been successfully captured.</p> </li> <li> <p>The proportion of UMIs mapped to genes in the mitochondrial genome; high proportions are indicative of poor-quality cells, possibly because of loss of cytoplasmic RNA from perforated cells (the reasoning is that mitochondria are larger than individual transcript molecules and less likely to escape through tears in the cell membrane).</p> </li> </ul> <p>The scater function <code>addPerCellQC()</code> will compute various per droplet QC metrics and will add this information as new columns in the droplet annotation (<code>colData</code>) of the single cell object.</p>"},{"location":"episodes/2/#load-multiple-samples","title":"Load multiple samples","text":"<p>We can load multiple samples at the same time using the read10xCounts command. This will create a single object containing the data for multiple samples. We can then QC and filter the samples in conjunction. As we will see later, this is not always optimal when samples have been processed in multiple batches.</p> <p>As an example we will load one sample from each sample group. We will start with the filtered counts matrix from earlier, which only contains cells called by CellRanger. We pass the read10xCounts a named vector containing the paths to the filtered counts matrices that we wish to load; the names of the vector will be used as the sample names in the Single Cell Experiment object.</p> <p>code</p> <pre><code>samples &lt;- samplesheet$Sample[c(1,5,7,9)]\nlist_of_files &lt;- str_c(\"Data/CellRanger_Outputs/\", \n                       samples, \n                       \"/outs/filtered_feature_bc_matrix\")\nnames(list_of_files) &lt;- samples\nlist_of_files\n\nsce &lt;- read10xCounts(list_of_files, col.names=TRUE, BPPARAM = bp.params)\nsce\n</code></pre> Output <pre><code>class: SingleCellExperiment \ndim: 37764 14809 \nmetadata(1): Samples\nassays(1): counts\nrownames(37764): ENSG00000243485 ENSG00000237613 ... ENSG00000278817 ENSG00000277196\nrowData names(3): ID Symbol Type\ncolnames(14809): 1_AAACCTGAGACTTTCG-1 1_AAACCTGGTCTTCAAG-1 ... 4_TTTGGTTAGGTGCTAG-1 4_TTTGGTTGTGCATCTA-1\ncolData names(2): Sample Barcode\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\n</code></pre>"},{"location":"episodes/2/#modify-the-droplet-annotation","title":"Modify the droplet annotation","text":"<p>Currently, the droplet annotation in <code>colData</code> slot of the <code>sce</code> object has two columns: \u201cSample\u201d and \u201cBarcode\u201d. The \u201cSample\u201d is the name of the sample as we provided it to <code>read10xCounts</code>, the \u201cBarcode\u201d is the barcode for the droplet (cell).</p> <p>code</p> <pre><code>colData(sce)\n</code></pre> <p>The \u201cBarcode\u201d column contains the cell/droplet barcode and comprises the actual sequence and a \u2018group ID\u2019, e.g. AAACCTGAGAAACCAT-1. The \u2018group ID\u2019 helps distinguish cells from different samples that have identical barcode sequences, however, as each sample was processed separately with CellRanger, the group ID is set to 1 in all data sets. In the rownames DropUtils has helpfully add a prefix to each barcode to distinguish between samples. We will replace the \u201cBarcode\u201d column with the these.</p> <p>We will also add information from the sample metadata table to the <code>colData</code> object. We will be using the merge function to do this. Unfortunately, this function removes the rownames from the DFrame, so we will need to replace them.</p> <p>code</p> <pre><code>sce$Barcode &lt;- rownames(colData(sce))\ncolData(sce) &lt;- merge(colData(sce), samplesheet, by=\"Sample\", sort=FALSE)\nrownames(colData(sce)) &lt;- sce$Barcode\n</code></pre>"},{"location":"episodes/2/#undetected-genes","title":"Undetected genes","text":"<p>Although the count matrix has 37764 genes, many of these will not have been detected in any droplet.</p> <p>About a fifth of the genes have not been detected in any droplet. We can remove these before proceeding in order to reduce the size of the single cell experiment object.</p> <p>code</p> <pre><code>detected_genes &lt;- rowSums(counts(sce)) &gt; 0\ntable(detected_genes)\nsce &lt;- sce[detected_genes,]\n</code></pre>"},{"location":"episodes/2/#annotate-genes","title":"Annotate genes","text":"<p>In order to assess the percentage of mitochondrial UMIs, we will need to be able to identify mitochondrial genes. The simplest way to do this is to annotate the genes with their chromosome of origin.</p> <p>There are many ways we could annotate our genes in R. We will use AnnotationHub. <code>AnnotationHub</code> has access to a large number of annotation databases. Our genes are currently annotated with Ensembl IDs, so we will use Ensembl human database. We will also specify that we want the database corresponding to Ensembl release 107 as this the release from which the CellRanger gene annotation was generated.</p> <p>code</p> <ul> <li>Running following command for the first time will prompt the question <code>/home/$USER/.cache/R/AnnotationHub does not exist, create directory? (yes/no):</code> . Reply <code>yes</code> to it </li> </ul> <p><pre><code>ah &lt;- AnnotationHub()\n</code></pre> <pre><code>ens.hs.107&lt;- query(ah, c(\"Homo sapiens\", \"EnsDb\", 107))[[1]] \n\ngenes &lt;- rowData(sce)$ID\ngene_annot &lt;- AnnotationDbi::select(ens.hs.107, \n                                    keys = genes,\n                                    keytype = \"GENEID\",\n                                    columns = c(\"GENEID\", \"SEQNAME\")) %&gt;%\n    set_names(c(\"ID\", \"Chromosome\"))\nrowData(sce) &lt;- merge(rowData(sce), gene_annot, by = \"ID\", sort=FALSE)\nrownames(rowData(sce)) &lt;- rowData(sce)$ID\n\nrowData(sce)\n</code></pre></p>"},{"location":"episodes/2/#add-per-cell-qc-metrics","title":"Add per cell QC metrics","text":"<p>We can now add per cell QC metrics to the droplet annotation using the function addPerCellQC. In order to get the metrics for the subset of mitochondrial genes, we need to pass the function a vector indicating which genes are mitochondrial.</p> <p>code</p> <pre><code>is.mito &lt;- which(rowData(sce)$Chromosome==\"MT\")\nsce &lt;- addPerCellQC(sce, subsets=list(Mito=is.mito), BPPARAM = SerialParam())\ncolData(sce)\n</code></pre> <p>Info</p> <p>The function has added six columns to the droplet annotation:</p> <ul> <li>sum: total UMI count</li> <li>detected: number of features (genes) detected</li> <li>subsets_Mito_sum: number of UMIs mapped to mitochondrial transcripts</li> <li>subsets_Mito_detected: number of mitochondrial genes detected</li> <li>subsets_Mito_percent: percentage of UMIs mapped to mitochondrial transcripts</li> <li>total: also the total UMI count</li> </ul> <p>We will use sum, detected, and subsets_Mito_percent to further filter the cells.</p>"},{"location":"episodes/2/#qc-metric-distribution","title":"QC metric distribution","text":"<p>Before moving on to do the actual cell filtering, it is always a good idea to explore the distribution of the metrics across the droplets.</p> <p>We can use the <code>scater</code> function <code>plotColData</code> to generate plots that provide a look at these distributions on a per sample basis.</p> <p>code</p> <p><pre><code>plotColData(sce, x=\"SampleName\", y=\"sum\") + \n    scale_y_log10() + \n    ggtitle(\"Total count\")\n</code></pre> </p> <p><pre><code>plotColData(sce, x=\"SampleName\", y=\"detected\") + \nscale_y_log10() + \nggtitle(\"Detected features\")\n</code></pre> </p> <pre><code>plotColData(sce, x=\"SampleName\", y=\"subsets_Mito_percent\") + \nggtitle(\"Mito percent\")\n</code></pre> <p></p> <p>A scatter plot shows the extent to which library size and numbers of genes detected are correlated.</p> <p><pre><code>colData(sce) %&gt;% \n    as.data.frame() %&gt;% \n    arrange(subsets_Mito_percent) %&gt;% \n    ggplot(aes(x = sum, y = detected)) +\n    geom_point(aes(colour = subsets_Mito_percent &gt; 10)) + \n    facet_wrap(vars(SampleGroup))\n</code></pre> </p>"},{"location":"episodes/2/#identification-of-low-quality-cells-with-adaptive-thresholds","title":"Identification of low-quality cells with adaptive thresholds","text":"<p>One could use hard threshold for the library size, number of genes detected and mitochondrial content based on the distributions seen above. These would need vary across runs and the decision making process is somewhat arbitrary. It may therefore be preferable to rely on outlier detection to identify cells that markedly differ from most cells.</p> <p>We saw above that the distribution of the QC metrics is close to Normal. Hence, we can detect outliers using the median and the median absolute deviation (MAD) from the median (not the mean and the standard deviation which both are sensitive to outliers).</p> <p>For a given metric, an outlier value is one that lies over some number of MADs away from the median. A cell will be excluded if it is an outlier in the part of the range to avoid, for example low gene counts, or high mitochondrial content. For a normal distribution, a threshold defined with a distance of 3 MADs from the median retains about 99% of values.</p> <p>The <code>scater</code> function <code>isOutlier</code> can be used to detect outlier cells based on any metric in the <code>colData</code> table. It returns a boolean vector that identifies outliers. By default it will mark any cell that is 3 MADS in either direction from the median as an outlier.</p>"},{"location":"episodes/2/#library-size","title":"Library size","text":"<p>With library size we wish to identify outliers that have very low library sizes, this indicates that the droplets either contain poor quality cells, perhaps damaged or dying, or do not contain a cell at all.</p> <p>The library size distribution tends to have a long tail to the right (small numbers of cells with very high UMI counts). We therefore log transform the library size in order to the make the distribution closer to normal. This also improves the resolution of the smaller library sizes and ensures that we do not end up with negative threshold.</p> <p>code</p> <pre><code>low_lib_size &lt;- isOutlier(sce$sum, log=TRUE, type=\"lower\")\ntable(low_lib_size)\n</code></pre> <ul> <li> <p>This has excluded 0 cells. We can view the threshold values to check that they seem reasonable. <pre><code>attr(low_lib_size, \"thresholds\")\n</code></pre></p> </li> <li> <p>We can view the effect of the filtering using <code>plotColData</code>. <pre><code>colData(sce)$low_lib_size &lt;- low_lib_size\nplotColData(sce, x=\"SampleName\", y=\"sum\", colour_by = \"low_lib_size\") + \n    scale_y_log10() + \n    labs(y = \"Total count\", title = \"Total count\") +\n    guides(colour=guide_legend(title=\"Discarded\"))\n</code></pre> </p> </li> </ul>"},{"location":"episodes/2/#number-of-genes","title":"Number of genes","text":"<p>As with the library size, we will log tranform the number of genes detected prior to filtering using the median absolute deviation.</p> <p>code</p> <pre><code>low_n_features &lt;- isOutlier(sce$detected, log=TRUE, type=\"lower\")\ntable(low_n_features)\n</code></pre> <ul> <li> <p>This has excluded out 173 cells. The threshold value was: <pre><code>attr(low_n_features, \"thresholds\")[1]\n</code></pre></p> </li> <li> <p>We can view the effect of the filtering using plotColData. <pre><code>colData(sce)$low_n_features &lt;- low_n_features\nplotColData(sce, x=\"SampleName\", y=\"detected\", colour_by = \"low_n_features\") + \n    scale_y_log10() + \n    labs(y = \"Genes detected\", title = \"Genes detected\") +\n    guides(colour=guide_legend(title=\"Discarded\"))\n</code></pre></p> </li> </ul> <p></p>"},{"location":"episodes/2/#mitochondrial-content","title":"Mitochondrial content","text":"<p>For the mitochondrial content the exclusion zone is in the higher part of the distribution. For this reason we do not need to worry about log transforming the data as want to remove the long right hand tail anyway.</p> <p>code</p> <pre><code>high_Mito_percent &lt;- isOutlier(sce$subsets_Mito_percent, type=\"higher\")\ntable(high_Mito_percent)  \n</code></pre> <ul> <li> <p>This has removed 1720 cells in total. The upper threshold value: <pre><code>attr(high_Mito_percent, \"thresholds\")[2]\n</code></pre></p> </li> <li> <p>We can view the effect of the filtering using plotColData. <pre><code>colData(sce)$high_Mito_percent &lt;- high_Mito_percent\nplotColData(sce,\n            x=\"SampleName\",\n            y=\"subsets_Mito_percent\",\n            colour_by = \"high_Mito_percent\") + \n    labs(y = \"Percentage mitochondrial UMIs\",\n         title = \"Mitochondrial UMIs\") +\n    guides(colour=guide_legend(title=\"Discarded\"))\n</code></pre> </p> </li> </ul>"},{"location":"episodes/2/#summary-of-discarded-cells","title":"Summary of discarded cells","text":"<p>Having applied each of the three thresholds separately, we can now combine them to see how many droplets in total we will be excluding.</p> <p>code</p> <pre><code>tibble(low_lib_size, low_n_features, high_Mito_percent) %&gt;%\n  mutate(discard = low_lib_size | low_n_features | high_Mito_percent) %&gt;% \n  mutate(SampleName=colData(sce)$SampleName) %&gt;% \n  group_by(SampleName)  %&gt;%\n  summarise(across(where(is.logical), sum))\n</code></pre>"},{"location":"episodes/2/#all-three-filter-steps-at-once","title":"All three filter steps at once","text":"<p>The three steps above may be run in one go using the quickPerCellQC function. This creates a DataFrame with 4 columns containing TRUE/FALSE - one for each filter metric and one called \u201cdiscard\u201d that combined the three logicals.</p> <p>code</p> <p><pre><code>cell_qc_results &lt;- quickPerCellQC(colData(sce), sub.fields = TRUE)\n</code></pre> <pre><code>cell_qc_results %&gt;%\n  as.data.frame() %&gt;% \n  mutate(SampleName=colData(sce)$SampleName) %&gt;% \n  group_by(SampleName) %&gt;%\n  summarise(across(where(is.logical), sum))\n</code></pre></p> Assumptions and considerations"},{"location":"episodes/2/#assumptions","title":"Assumptions","text":"<p>Data quality depends on the tissue analysed, some being difficult to dissociate, e.g. brain, so that one level of QC stringency will not fit all data sets.</p> <p>Filtering based on QC metrics as done here assumes that these QC metrics are not correlated with biology. This may not necessarily be true in highly heterogenous data sets where some cell types represented by good-quality cells may have low RNA content or high mitochondrial content.</p>"},{"location":"episodes/2/#considering-experimental-factors-when-filtering","title":"Considering experimental factors when filtering","text":"<p>The samples analysed here may have been processed in different batches leading to differences in the overall distribution of UMI counts, numbers of genes detected and mitochondrial content. Such differences would affect the adaptive thresholds discussed above - that is, as the distributions of the metrics differ, perhaps we should really apply the adaptive thresholding for each batch rather than universally across all samples. The `quickPerCellQC has a \u201cbatch\u201d argument that allows us to specify with samples belong to which batches. The batches are then filtered independently.</p> <p>code</p> <p><pre><code>batch.cell_qc_results &lt;- quickPerCellQC(colData(sce), \n                                     sub.fields = TRUE,\n                                     batch=sce$Sample)\n</code></pre> <pre><code>batch.cell_qc_results %&gt;%\n  as.data.frame() %&gt;% \n  mutate(SampleName=colData(sce)$SampleName) %&gt;% \n  group_by(SampleName) %&gt;%\n  summarise(across(where(is.logical), sum))\n</code></pre></p> <p>The table below shows how the thresholds for each metric differ between the batch-wise analysis and the analysis using all samples.</p> <p>code</p> <p><pre><code>all.thresholds &lt;- tibble(`SampleName`=\"All\",\n                          `Library Size`=attr(cell_qc_results$low_lib_size, \"thresholds\")[1],\n                         `Genes detected`=attr(cell_qc_results$low_n_features, \"thresholds\")[1],\n                          `Mitochondrial UMIs`=attr(cell_qc_results$high_subsets_Mito_percent, \"thresholds\")[2])\n\n\n tibble(`Sample`=names(attr(batch.cell_qc_results$low_lib_size, \"thresholds\")[1,]),\n        `Library Size`=attr(batch.cell_qc_results$low_lib_size, \"thresholds\")[1,],\n       `Genes detected`=attr(batch.cell_qc_results$low_n_features, \"thresholds\")[1,],\n       `Mitochondrial UMIs`=attr(batch.cell_qc_results$high_subsets_Mito_percent, \"thresholds\")[2,]) %&gt;% \n  left_join(samplesheet) %&gt;% \n  dplyr::select(SampleName, `Library Size`, `Genes detected`, `Mitochondrial UMIs`) %&gt;% \n  bind_rows(all.thresholds) %&gt;% \n   mutate(across(where(is.numeric), round, digits=2))\n</code></pre> SampleName Library Size Genes detected Mitochondrial UMIs ETV6-RUNX1_1 1475.79 1018.21 9.56 HHD_1 297.78 318.38 12.14 PRE-T_1 252.52 382.36 6.24 PBMMC_1 580.14 496 7.23 All 373.1 387.88 11.14 <p></p> <ul> <li>Let\u2019s replace the columns in the droplet annotation with these new filters.</li> </ul> <pre><code>sce$low_lib_size &lt;- batch.cell_qc_results$low_lib_size\nsce$low_n_features &lt;- batch.cell_qc_results$low_n_features\nsce$high_Mito_percent &lt;- batch.cell_qc_results$high_subsets_Mito_percent\nsce$discard &lt;- batch.cell_qc_results$discard\n</code></pre> <ul> <li> <p>We can visualise how the new filters look using violin plots.</p> <p><pre><code>plotColData(sce, x=\"SampleName\", y=\"sum\", colour_by = \"low_lib_size\") + \n   scale_y_log10() + \n   labs(y = \"Total count\", title = \"Total count\") +\n   guides(colour=guide_legend(title=\"Discarded\"))\n</code></pre> </p> <pre><code>  plotColData(sce, x=\"SampleName\", y=\"detected\", colour_by = \"low_n_features\") + \n    scale_y_log10() + \n     labs(y = \"Genes detected\", title = \"Genes detected\") +\n     guides(colour=guide_legend(title=\"Discarded\"))\n</code></pre> <p></p> <ul> <li>There are some distinct differences, most noticeable is that some cells are now being filtered based on library size for both ETV6-RUNX1_1 and PBMMC_1a. The venn diagrams below show how the number of discarded droplets in have changed for each filter in comparison to when the MAD filtering was applied across all samples.</li> </ul> <p><pre><code>pc1 &lt;- tibble(`All together`=cell_qc_results$low_lib_size, \n             `By batch`=batch.cell_qc_results$low_lib_size) %&gt;% \n          ggvenn(show_percentage = FALSE) +\n              labs(title=\"Library Size\")\n\npc2 &lt;- tibble(`All together`=cell_qc_results$low_n_features, \n             `By batch`=batch.cell_qc_results$low_n_features) %&gt;% \n          ggvenn(show_percentage = FALSE) +\n              labs(title=\"Genes detected\")\n\npc3 &lt;- tibble(`All together`=cell_qc_results$high_subsets_Mito_percent, \n                `By batch`=batch.cell_qc_results$high_subsets_Mito_percent) %&gt;% \n           ggvenn(show_percentage = FALSE) +\n              labs(title=\"Mitochondrial UMIs\")\n</code></pre> <pre><code>p   c1 + pc2 + pc3\n</code></pre> </p> <ul> <li>The most striking difference is in the filtering by library size. As we can see from the violin plots ETV6-RUNX1_1 has a markedly different library size distribution to the other three samples. When we applied the adaptive filters across all samples, the lower distributions of the other three samples caused the MADs to be distorted and resulted in a threshold that was inappropriately low for the ETV6-RUNX1_1 samples.</li> </ul> </li> </ul>"},{"location":"episodes/2/#filtering-out-poor-quality-cells","title":"Filtering out poor quality cells","text":"<p>Now that we have identified poor quality cells we can filter them out before proceeding to do any further analysis.</p> <p>code</p> <pre><code>sce.filtered &lt;- sce[, !sce$discard]\n</code></pre>"},{"location":"episodes/2/#qc-and-filtering-by-combining-the-metrics","title":"QC and filtering by combining the metrics","text":"<p>In the previous approach we used the three metrics in isolation to filter droplets. Another approach is to combine the three (or more) metrics in a single filtering step by looking for outliers in the multi-dimensional space defined by the metrics.</p> <p>As with the adaptive thresholds above, this method should not be applied across batches or samples with differing distributions in the metrics or it will exclude many good quality cells. To demonstrate these methods, we\u2019ll just extract one sample from our SingleCellExperiment object.</p> <p>code</p> <pre><code>sce.E1 &lt;- sce[ , sce$SampleName == \"ETV6-RUNX1_1\"]\n</code></pre>"},{"location":"episodes/2/#using-outlyingness","title":"Using \u201coutlyingness\u201d","text":"<p>Essentially we need to reduce our three metrics to a single metric, we can then use isOutlier to select outliers based on this metric. One way to do this is to use the function adjOutlyingness from the robustbase package. This function computes the \u201coutlyingness\u201d for each droplet.</p> <p>Here we will use the same three metrics as before: library size, the number of genes detected and the mitochondrial content. Remember that for \u201csum\u201d (total UMIs) and \u201cdetected\u201d (number of genes detected), we want to use the log10 value.</p> <p>code</p> <pre><code>library(robustbase)\nstats &lt;- cbind(log10(sce.E1$sum),\n               log10(sce.E1$detected),\n               sce.E1$subsets_Mito_percent)\n\noutlying &lt;- adjOutlyingness(stats, only.outlyingness = TRUE)\nmulti.outlier &lt;- isOutlier(outlying, type = \"higher\")\nsummary(multi.outlier)\n</code></pre>"},{"location":"episodes/2/#using-pca","title":"Using PCA","text":"<p>Another approach is to perform a principal component analysis (PCA) on the table of metrics, apply <code>adjOutlyingness</code> to the metrics table and use this to detect outliers. The <code>scater</code> function <code>runColDataPCA</code> can be used to perform the PCA and detect outliers. We\u2019ll need to add a couple of columns to the <code>colData</code> for the log10 metrics first.</p> <p>code</p> <pre><code>sce.E1$log10sum &lt;- log10(sce.E1$sum)\nsce.E1$log10detected &lt;- log10(sce.E1$detected)\nsce.E1 &lt;- runColDataPCA(sce.E1, \n                     variables=list(\"log10sum\", \n                                    \"log10detected\", \n                                    \"subsets_Mito_percent\"),\n                     outliers=TRUE,\n                     BPPARAM = bp.params)\n</code></pre> <ul> <li>This has added the results of the principal component analysis into a new slot in the SingleCellExperiment object specifically for holding the results of dimension reduction transformations such as PCA, t-SNE and UMAP. The results can be accessed using the <code>reducedDim</code> function. <pre><code>head(reducedDim(sce.E1))\n</code></pre></li> <li>It has also added a column \u201coutlier\u201d to the <code>colData</code>, which specifies the droplets that have been identified as outliers. <pre><code>summary(sce.E1$outlier)\n</code></pre></li> </ul>"},{"location":"episodes/2/#a-note-on-multi-dimensional-filtering","title":"A note on multi-dimensional filtering","text":"<p>These types of approach can provide more power for detecting outliers as they are looking at patterns across multiple metrics, however, it can be difficult to interpret the reason why any particular droplet has been excluded.</p>"},{"location":"episodes/2/#mitochondrial-content-versus-library-size","title":"Mitochondrial content versus library size","text":"<p>A useful diagnostic plot for assessing the impact of the filtering is to do a scatter plot of the mitochondrial content against the library size. We can overlay our final filter metric using the point colour.</p> <p>code</p> <pre><code>plotColData(sce, \n            x=\"sum\", \n            y=\"subsets_Mito_percent\", \n            other_fields=\"SampleName\",\n            colour_by=\"discard\") +\n    facet_wrap(~SampleName, ncol=5, scale=\"free_x\")\n</code></pre> <p></p>"},{"location":"episodes/3/","title":"3. Normalisation","text":"<p>code</p> <pre><code>library(scater)\nlibrary(scran)\nlibrary(sctransform)\nlibrary(tidyverse)\nlibrary(BiocParallel)\nlibrary(patchwork)\nbpp &lt;- MulticoreParam(4)\n</code></pre>"},{"location":"episodes/3/#load-data-object","title":"Load data object","text":"<p>For the purposes of this demonstration we have generated a smaller data set in which there are only 500 cells per sample. This is so that the code can be run in a reasonable amount of time during the live teaching session. The data were first QC\u2019d and filtered as described in the QC and exploratory analysis session. After this 500 cells were selected at random from each sample.</p> <p>code</p> <pre><code>sce &lt;- readRDS(\"R_objects/Caron_filtered.500.rds\")\nsce\n</code></pre> Output <pre><code>class: SingleCellExperiment \ndim: 29346 5500 \nmetadata(1): Samples\nassays(1): counts\nrownames(29346): ENSG00000243485 ENSG00000238009 ... ENSG00000275063 ENSG00000278817\nrowData names(4): ID Symbol Type Chromosome\ncolnames(5500): 1_CGACTTCGTCCAGTTA-1 1_AGAATAGCATACGCTA-1 ... 8_AGCGTCGAGATGTAAC-1 8_CATGACAAGATAGGAG-1\ncolData names(10): Sample Barcode ... subsets_Mito_percent total\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\n</code></pre> <pre><code>table(sce$SampleName)\n</code></pre>"},{"location":"episodes/3/#why-normalise","title":"Why normalise ?","text":"<p>code</p> <p><pre><code>oneSamTab &lt;- colData(sce) %&gt;% \n  as.data.frame() %&gt;% \n  dplyr::filter(SampleName == \"PBMMC_1\") %&gt;% \n  dplyr::select(SampleName,Barcode, sum) %&gt;% \n  mutate(cell_num = 1:n())\n\np_before_nom &lt;- ggplot(data=oneSamTab, aes(x=cell_num, y=sum)) +\n  geom_bar(stat = 'identity') +\n  labs( x= 'Cell Index',\n        y='Cell UMI counts',\n        title = \"PBMMC_1: Before Normalization\" ) +\n  theme_classic() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size=20, color = 'red')\n  )\n\np_before_nom\n</code></pre> </p> <ul> <li> <p>Above plot shows the UMI counts/cell (transcript molecules) for 500 cell from the PBMMC_1 sample</p> </li> <li> <p>UMI counts fluctuate</p> </li> <li> <p>We derive biological insights downstream by comparing cells against each other.</p> </li> <li> <p>But the UMI counts differences makes it harder to compare cells.</p> </li> <li> <p>Why total transcript molecules (UMI counts) detected between cells differ?</p> <ul> <li> <p>Biological:</p> <ul> <li>Cell sub type differences, like size and transcription activity etc.</li> </ul> </li> <li> <p>Technical: scRNA data is inherently noisy</p> <ul> <li>Low mRNA content per cell</li> <li>cell-to-cell differences in mRNA capture efficiency</li> <li>Variable sequencing depth</li> <li>PCR amplification efficiency</li> </ul> </li> </ul> </li> <li> <p>A normalization technique makes the UMI counts distribution uniform, so that each cell has similar counts.</p> </li> <li> <p>Normalization is a critical step that corrects cell-to-cell technical differences.</p> </li> <li> <p>By normalizing, downstream comparisons of relative expression between cells are valid.</p> </li> </ul>"},{"location":"episodes/3/#normalization-strategies","title":"Normalization strategies","text":"<p>The sparse nature of scRNA data makes normalization difficult, unlike bulk RNAseq data</p> <p>Broadly two classes:</p> <ul> <li> <p>Spike-in methods</p> <ul> <li>Uses spike-in controls for normalisation</li> <li>Not available for droplet based scRNA techniques like 10x.</li> </ul> </li> <li> <p>Non-spike-in methods: </p> <ul> <li>Using available counts data for normalization</li> <li>DEseq2</li> <li>edgeR-TMM</li> <li>Library size normalization</li> <li>deconvolution</li> <li>sctransform</li> </ul> </li> </ul> <p>Typical normalization has two steps:</p> <ul> <li> <p>Scaling</p> <ul> <li>Estimate size or scaling or normalization factor: computation of a cell-specific \u2018scaling\u2019 or \u2018size\u2019 factor or \u201cnormalization factor\u201d that represents the relative bias in that cell and division of all counts for the cell by that factor to remove that bias. Assumption: any cell specific bias will affect genes the same way.</li> <li>Scale the data by dividing the count for each gene with the appropriate size factor for that cell        </li> </ul> </li> <li> <p>Transformation</p> <ul> <li>log2</li> <li>Square root transformation</li> <li>Pearson residuals (eg. sctransform)</li> </ul> </li> </ul> <p>Scaling methods typically generate normalised counts-per-million (CPM) or transcripts-per-million (TPM) values that address the effect of sequencing depth. These values however typically have a variance that increases with their mean (heteroscedasticity) while most statistical methods assume a stable variance, which does not vary with the mean (homoscedasticity). A widely used \u2018variance stabilising transformation\u2019 is the log transformation (often log2). This works well for highly expressed genes (as in bulk RNA-seq) but less so for sparse scRNA-seq data.</p> <p> * DEseq, edgeR-TMM and Library size normalization initially developed for bulk RNAseq * Applying these methods on scRNAseq data systematically under or over estimate size factors. i.e systematically deviate from true size factors. * This deviation is the result of removing zeroes prior to normalization. * Therefore other normalization methods specific to scRNAseq data like deconvolution, sctransform etc. were proposed.</p>"},{"location":"episodes/3/#deconvolution","title":"Deconvolution","text":"<p>Because single-cell data tend to have a substantial number of low and zero counts, these bulk normalization methods may be problematic for single-cell data.</p> <ul> <li>Deconvolution aims to normalize expression values based on summed values from pools of cells.</li> <li>Since cell summation results in fewer zeros, the ensuing normalization is less susceptible to errors than existing methods.</li> <li>The estimated size factors are only relevant to the pools of cells, even though normalization accuracy has improved.</li> <li>Each pool\u2019s size factor is deconvolved into its constituent cells\u2019 size factors.</li> </ul> <p>The deconvolution method consists of several key steps:</p> <p>References: https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-0947-7</p> <ul> <li>Defining a pool of cells</li> <li>Summing expression values across all cells in the pool</li> <li>Normalizing the cell pool against an average reference, using the summed expression values</li> <li>Repeating this for many different pools of cells to construct a linear system</li> <li>Deconvolving the pool-based size factors to their cell-based counterparts </li> </ul> <p></p> <p>Schematic of the deconvolution method. All cells in the data set are averaged to make a reference pseudo-cell. Expression values for cells in pool A are summed together and normalised against the reference to yield a pool-based size factor \u03b8<sub>A</sub> . This is equal to the sum of the cell-based factors \u03b8<sub>j</sub> for cells j=1\u20134 and can be used to formulate a linear equation. (For simplicity, the t<sub>j</sub> term is assumed to be unity here.) Repeating this for multiple pools (e.g., pool B) leads to the construction of a linear system that can be solved to estimate \u03b8<sub>j</sub> for each cell j</p> <p>In order to avoid pooling cells with radically different transcriptomic profiles, the cells are first clustered based on gene expression. The pools are then formed exclusively with each cluster. Size factors are calculated within each cluster and are then scaled so they are comparable across clusters.</p>"},{"location":"episodes/3/#cluster-cells","title":"Cluster Cells","text":"<p>The table below show the number and size of clusters found:</p> <p>code</p> <pre><code>set.seed(100)\nclust &lt;- quickCluster(sce, BPPARAM=bpp)\ntable(clust)\n</code></pre>"},{"location":"episodes/3/#compute-size-factors","title":"Compute size factors","text":"<p>code</p> <p><pre><code>sce &lt;- computePooledFactors(sce,\n             clusters = clust,\n             min.mean = 0.1,\n             BPPARAM = bpp)\ndeconv.sf &lt;- sizeFactors(sce)\nsummary(deconv.sf)\n</code></pre> Note: min.mean - A numeric scalar specifying the minimum (library size-adjusted) average count of genes to be used for normalization. This means large numbers of very lowly expressed genes will not bias the normalization.</p> <p>Plot deconvolution size factors against library size factors:</p> <p><pre><code>lib.sf &lt;- librarySizeFactors(sce)\ndata.frame(LibrarySizeFactors = lib.sf, \n           DeconvolutionSizeFactors = deconv.sf,\n                 SampleGroup = sce$SampleGroup) %&gt;%\n  ggplot(aes(x=LibrarySizeFactors, y=DeconvolutionSizeFactors)) +\n      geom_point(aes(col=SampleGroup)) +\n      geom_abline(slope = 1, intercept = 0)\n</code></pre> </p>"},{"location":"episodes/3/#apply-size-factors","title":"Apply size factors","text":"<p>For each cell, raw counts for genes are divided by the size factor for that cell and log-transformed so downstream analyses focus on genes with strong relative differences. We use <code>scater::logNormCounts()</code>.</p> <p>code</p> <pre><code>sce &lt;- logNormCounts(sce)\nassayNames(sce)\n</code></pre>"},{"location":"episodes/3/#explore-the-effect-of-normalisation","title":"Explore the effect of normalisation","text":"<p>Normalised counts are much less variable across cells than raw counts</p> <p>code</p> <p><pre><code>norm_counts &lt;- logNormCounts(sce,transform='none' ) %&gt;% \n  assay('normcounts') %&gt;% \n  as.matrix() %&gt;% \n  colSums()\nnorm_counts &lt;- tibble(Barcode=names(norm_counts),\n                      normCounts = log2(norm_counts)\n                      )\nnorm_counts &lt;- inner_join(norm_counts, oneSamTab, by='Barcode')\n\n\np_after_norm &lt;- ggplot(data=norm_counts, aes(x=cell_num, y=normCounts)) +\n  geom_bar(stat = 'identity') +\n  labs( x= 'Cell Index',\n        y='Normalized Cell UMI counts',\n        title = \"PBMMC_1:After Normalization\" ) +\n  theme_classic() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size=20, color = 'red')\n  )\n\np_before_nom + p_after_norm\n</code></pre> </p> <p>Let\u2019s separate out the scaling normalisation from the log transformation</p> <p>What do the un-normalised data look like if we log them?</p> <pre><code>p_before_norm_log &lt;- ggplot(data=oneSamTab, aes(x=cell_num, y=log2(sum))) +\n  geom_bar(stat = 'identity') +\n  labs( x= 'Cell Index',\n        y='Cell UMI counts',\n        title = \"Logged raw counts\" ) +\n  theme_classic() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size=20, color = 'red')\n  )\n\np_before_norm_log + p_after_norm\n</code></pre> <p></p> <p>Simply logging the sum of counts per cell reduces the variation a lot, but the scaling is required to do the job properly.</p> <p>The log transformation is meant to reduce the correlation between mean and variance for genes - has this worked?</p> <p>We can look at the relationship between the mean gene expression and variance for raw UMI counts, scaled counts and scaled, logged counts.</p> <p>For raw counts: <pre><code># mean and variance for raw counts\nmean &lt;- rowMeans(assay(sce, \"counts\"))\nvar &lt;- rowVars(assay(sce, \"counts\"))\n</code></pre> <pre><code># Scatter plot\nplot(log(mean), log(var), main = \"raw data\")\nabline(a=1, b=1, col=\"red\")\n</code></pre> </p> <p>There is a strong linear relationship between mean and variance of UMI counts across genes.</p> <p>For scaled counts:</p> <p><pre><code># Mean and variance for scaled counts\nmean_scaled &lt;- logNormCounts(sce,transform='none' ) %&gt;% \n  assay('normcounts') %&gt;% \n  rowMeans()\nvar_scaled &lt;- logNormCounts(sce,transform='none' ) %&gt;% \n  assay('normcounts') %&gt;% \n  rowVars()\n\nplot(log(mean_scaled), log(var_scaled), main = 'scaled data')\nabline(a=1, b=1, col=\"red\")\n</code></pre> </p> <p>The relationship is still there after scaling the counts.</p> <p>For scaled, log transformed counts:</p> <p><pre><code># Mean and variance for scaled, log transformed counts\nmean_norm &lt;- rowMeans(assay(sce, \"logcounts\"))\nvar_norm &lt;- rowVars(assay(sce, \"logcounts\"))\n\nplot(mean_norm, var_norm, main = 'scaled, log transformed)\nabline(a=1, b=1, col=\"red\")\n</code></pre> </p> <p>We see that the log transformation removes a large part of the relationship between mean and variance for gene expression values.</p>"},{"location":"episodes/3/#save-the-normalised-object","title":"Save the normalised object","text":"<p>Make sure to create the <code>results</code> directory first.</p> <p>code</p> <pre><code>saveRDS(sce, \"results/caron_normalised.rds\")\n</code></pre> Exercise <p>Apply the deconvolution normalisation on a single sample: ETV6-RUNX1_1.</p> <p>You will first load the a single cell experiment object containing the entire Caron data set. First it is necessary to select only cells that came from the sample \u2018ETV6-RUNX1_1\u2019. You can then apply the normalization by deconvolution by clustering the cells, computing size factors and using these to log-normalize the counts.</p>"},{"location":"episodes/4/","title":"4. sctransform: Variance Stabilising Transformation","text":"<p>With scaling normalisation a correlation remains between the mean and variation of expression (heteroskedasticity). This affects downstream dimensionality reduction as the few main new dimensions are usually correlated with library size. <code>sctransform</code> addresses the issue by regressing library size out of raw counts and providing residuals to use as normalized and variance-stabilized expression values in some downstream analyses, such as dimensionality reduction.</p> <p>The <code>sctransform</code> package is from the Seurat suite of scRNAseq analysis packages. Rather than convert our Single Cell Experiment object into a Seurat object and use the Seurat package\u2019s command <code>SCTransform</code>, we will extract the counts matrix from our SCE object and run the variance stabilising transformation (VST) algorithm, using the <code>sctranform</code> package\u2019s vst command, directly on the matrix. We can extract the counts matrix - as a dgCMatrix object sparse matrix - using the <code>counts</code> function.</p> <p>code</p> <pre><code>counts &lt;- counts(sce)\nclass(counts)\n</code></pre>"},{"location":"episodes/4/#rationale","title":"Rationale","text":"<p>In order to demonstrate the rationale behind the using the variance stabilising transformation, we will visually inspect various properties of our data. Our main interest is in the general trends, not in individual outliers. Neither genes nor cells that stand out are important at this step; we focus on the global trends.</p>"},{"location":"episodes/4/#derive-gene-and-cell-attributes-from-the-umi-matrix","title":"Derive gene and cell attributes from the UMI matrix","text":""},{"location":"episodes/4/#gene-attributes","title":"Gene attributes","text":"<p>Each gene has four attributes:</p> <ul> <li>mean UMI count across cells</li> <li>number of cells where the gene is detected</li> <li>variance of UMI counts across cells</li> <li>the mean and variance above on the log10 scale </li> </ul> <p>code</p> <p><pre><code>gene_attr &lt;- data.frame(mean = rowMeans(counts), \n                        detection_rate = rowMeans(counts &gt; 0),\n                        var = rowVars(counts)) %&gt;% \n  mutate(log_mean = log10(mean)) %&gt;% \n  mutate(log_var = log10(var))\n</code></pre> <pre><code>dim(gene_attr)\n</code></pre> <pre><code>head(gene_attr)\n</code></pre></p>"},{"location":"episodes/4/#cell-attributes","title":"Cell attributes","text":"<p>Each cell has two attributes:</p> <ul> <li>total UMI count across genes (library size)</li> <li>number of genes detected (with at least 1 UMI)</li> </ul> <p>code</p> <p><pre><code>cell_attr &lt;- data.frame(n_umi = colSums(counts),\n                        n_gene = colSums(counts &gt; 0))\n</code></pre> <pre><code>dim(cell_attr)\n</code></pre> <pre><code>head(cell_attr)\n</code></pre></p>"},{"location":"episodes/4/#mean-variance-relationship","title":"Mean-variance relationship","text":"<p>For the genes, on the log10 scale we can see that up to a mean UMI count of 0 the variance follows the line through the origin with slope one, i.e. variance and mean are roughly equal as expected under a Poisson model. However, genes with a higher average UMI count show overdispersion compared to Poisson.</p> <p>code</p> <pre><code>ggplot(gene_attr, aes(log_mean, log_var)) + \n  geom_point(alpha=0.3, shape=16) +\n  geom_abline(intercept = 0, slope = 1, color='red')\n</code></pre> <p></p>"},{"location":"episodes/4/#mean-detection-rate-relationship","title":"Mean-detection-rate relationship","text":"<p>In line with the previous plot, we see a lower than expected detection rate in the medium expression range. However, for the highly expressed genes, the rate is at or very close to 1.0 suggesting that there is no zero-inflation in the counts for those genes and that zero-inflation is a result of overdispersion, rather than an independent systematic bias.</p> <p>code</p> <p><pre><code>x = seq(from = -3, to = 2, length.out = 1000)\npoisson_model &lt;- data.frame(log_mean = x,\n                detection_rate = 1 - dpois(0, lambda = 10^x))\n</code></pre> <pre><code>ggplot(gene_attr, aes(log_mean, detection_rate)) + \n  geom_point(alpha=0.3, shape=16) + \n  geom_line(data=poisson_model, color='red') +\n  theme_gray(base_size = 8)\n</code></pre></p> <p></p>"},{"location":"episodes/4/#cell-attributes_1","title":"Cell attributes","text":"<p>The plot below shows the relationship between the two cell attributes computed: library size (n_umi) and number of genes detected (n_gene).</p> <p>code</p> <pre><code>ggplot(cell_attr, aes(n_umi, n_gene)) + \n  geom_point(alpha=0.3, shape=16) + \n  geom_density_2d(size = 0.3)\n</code></pre> <p> </p>"},{"location":"episodes/4/#method","title":"Method","text":"<p>From the sctransform vignette: </p> <p>\u201cBased on the observations above, which are not unique to this particular data set, we propose to model the expression of each gene as a negative binomial random variable with a mean that depends on other variables. Here the other variables can be used to model the differences in sequencing depth between cells and are used as independent variables in a regression model. In order to avoid overfitting, we will first fit model parameters per gene, and then use the relationship between gene mean and parameter values to fit parameters, thereby combining information across genes. Given the fitted model parameters, we transform each observed UMI count into a Pearson residual which can be interpreted as the number of standard deviations an observed count was away from the expected mean. If the model accurately describes the mean-variance relationship and the dependency of mean and latent factors, then the result should have mean zero and a stable variance across the range of expression.\u201d</p> <p>Summary:</p> <ul> <li>expression of a gene is modeled by a negative binomial random variable with a mean that depends on library size.</li> <li>library size is used as the independent variable in a regression model.</li> <li>the model is fit for each gene, then combined data across genes is used to fit parameters.</li> <li>convert UMI counts to residuals akin to the number of standard deviations away from the expected mean.</li> </ul> <p>Assumptions:</p> <ul> <li>accurate model of the mean-variance relationship.</li> <li>accurate model of the dependency of mean and latent factors.</li> </ul> <p>Outcome:</p> <ul> <li>the mean of the transformed data (residuals) is zero.</li> <li>stable variance across expression range.</li> </ul>"},{"location":"episodes/4/#application","title":"Application","text":""},{"location":"episodes/4/#estimation-and-transformation","title":"Estimation and transformation","text":"<p>We will now estimate model parameters and transform data.</p> <p>The vst function estimates model parameters and performs the variance stabilizing transformation.</p> <p>Here we use the log10 of the total UMI counts of a cell as variable for sequencing depth for each cell. After data transformation we plot the model parameters as a function of gene mean (geometric mean). We will set the following arguments:</p> <ul> <li><code>umi</code> - The matrix of UMI counts with genes as rows and cells as columns</li> <li><code>latent_var</code> - The independent variables to regress out as a character vector</li> <li><code>return_gene_attr</code> - Make cell attributes part of the output</li> <li><code>return_cell_attr</code> - Calculate gene attributes and make part of output</li> </ul> <p>code</p> <p><pre><code>set.seed(44)\n</code></pre> <pre><code>vst_out &lt;- vst(umi = counts,\n               latent_var = c('log_umi'),\n               return_gene_attr = TRUE,\n               return_cell_attr = TRUE\n\n  )\n</code></pre></p>"},{"location":"episodes/4/#paramater-plots","title":"Paramater plots","text":"<p>We will generate some diagnostic plots in order to inspect the estimated and fitted model parameters.</p> <p>By default parameters shown are:</p> <ul> <li>intercept</li> <li>latent variables, here log_umi</li> <li>overdispersion factor (od_factor)</li> </ul> <p>code</p> <p><pre><code>plot_model_pars(vst_out)\n</code></pre> </p> <p>code</p> <p>We check the regression model used is the one the we intended:</p> <p><pre><code>vst_out$model_str\n</code></pre> We will now look at several genes in more detail by plotting observed UMI counts and comparing these to plots using the residuals from the modelling.</p> <p>For each gene of interest, we will plot:</p> <ul> <li>the observed cell attribute (UMI counts) against the latent variable (library size) (by default), with the fitted model as a pink line showing the expected UMI counts given the model and a shaded region spanning one standard deviation from the expected value.</li> <li>the residuals against the latent variable in the same way.</li> </ul> <p>We will look at two genes: \u2018RPL10\u2019 and \u2018HBB\u2019:</p> <p><pre><code>ensId &lt;- rowData(sce) %&gt;%\n    as.data.frame %&gt;%\n    dplyr::filter(Symbol %in% c('RPL10', 'HBB')) %&gt;%\n  pull(\"ID\")\n\nplot_model(x = vst_out,\n           umi = counts,\n           goi = ensId,\n           plot_residual = TRUE)\n</code></pre> </p>"},{"location":"episodes/4/#overall-properties-of-transformed-data","title":"Overall properties of transformed data","text":"<p>code</p> <ul> <li>The distribution of residual mean is centered around 0:</li> </ul> <p><pre><code>ggplot(vst_out$gene_attr, aes(x = residual_mean)) +\n    geom_histogram(binwidth=0.01)\n</code></pre> </p> <ul> <li>The distribution of residual variance is centered around 1:</li> </ul> <p><pre><code>ggplot(vst_out$gene_attr, aes(residual_variance)) +\n    geom_histogram(binwidth=0.1) +\n    geom_vline(xintercept=1, color='red') +\n    xlim(0, 10)\n</code></pre> </p> <ul> <li>Plotting the residual variance against the mean shows that after transformation there is no relationship between gene mean and variance.</li> </ul> <p><pre><code>ggplot(vst_out$gene_attr, aes(x = log10(gmean), y = residual_variance)) +\n       geom_point(alpha=0.3, shape=16)\n</code></pre> </p> <ul> <li>Check genes with large residual variance. These genes would be markers of expected cell populations. Note how they represent a great range of mean UMI and detection rate values.</li> </ul> <pre><code>vst_out$gene_attr %&gt;%\n  arrange(desc(residual_variance)) %&gt;% \n    top_n(n = 10) %&gt;%\n    mutate(across(where(is.numeric), round, 2)) %&gt;% \n  rownames_to_column(\"ID\") %&gt;%\n  left_join(as.data.frame(rowData(sce))[,c(\"ID\", \"Symbol\")], \"ID\")\n</code></pre>"},{"location":"episodes/4/#store-vst-transformed-data-in-the-sce-object","title":"Store VST transformed data in the SCE object","text":"<p>In order to store the transformed values in our Single Cell object, we need to add them as a new \u201cassay\u201d. The transformed values are kept as a matrix in the y object within vst_out.</p> <p>Note that, by default, genes that are expressed in fewer than 5 cells are not used by vst and results for these genes are not returned, so to add the \"y\" column from the vst_out object as an assay in our single cell object we may need to subset the rows of our sce object to match the rows of the vst_out y column. In our case, about 10,000 genes were expressed in less than 5 cells, so we will need to subset our SCE object before adding the VST normalised counts.</p> <p>code</p> <pre><code>keepGenes &lt;- rownames(sce)%in%rownames(vst_out$y)\nsce &lt;- sce[keepGenes,]\nvstMat &lt;- as(vst_out$y[rownames(sce),], \"dgCMatrix\")\n\nassay(sce, \"sctrans_norm\", withDimnames=FALSE) &lt;- vstMat\n</code></pre>"},{"location":"episodes/5/","title":"5. Feature Selection and Dimensionality Reduction","text":"<p>In this section we are going to cover the basics of feature selection and dimensionality reduction. These methods allow us to represent our multi-dimensional data (with thousands of cells and thousands of genes) in a reduced set of dimensions for visualisation and more efficient downstream analysis.</p> <p>In feature selection the principle is to remove those genes which are uninteresting or uninformative to both improve computation and because this \u2018noise\u2019 reduction will hopefully enable us to more clearly see the true biology in our data. We make the assumption that most of the low level variance is not caused by real biology and is due to stochastic sampling in the single cell protocol and various other technical effects. The genes which have the most variance are therefore the ones that reflect the real biological difference and are what we want to focus on. This is obviously not a perfect assumption but it is a good way to make informed interpretations from your data that you can hopefully have a little more confidence in.</p> <p>In dimensionality reduction we attempt to find a way to represent all the the information we have in expression space in a way that we can easily interpret. High dimensional data has several issues. There is a high computational requirement to performing analysis on 30,000 genes and 48,000 cells (in the Caron dataset). Humans live in a 3D world; we can\u2019t easily visualise all the dimensions. And then there is sparsity. As the number of dimensions increases the distance between two data points increases and becomes more invariant. This invariance causes us problems when we try to cluster the data into biologically similar groupings. By applying some dimensionality reducing methods we can solve these issues to a level where we can make interpretations</p> <p>Setup</p> <p>code</p> <pre><code>library(scater) \nlibrary(scran)\nlibrary(PCAtools)\nlibrary(tidyverse)\n</code></pre> <p>We will load the SingleCellExperiment object generated in the Normalisation section, which contains normalised counts for 500 cells per sample. For demonstration purposes we are not using the full dataset but you would in your analyses.</p> <p><pre><code>sce &lt;- readRDS(\"R_objects/Caron_normalized.500.rds\")\nsce\n</code></pre> - To make some of our plots later on easier to interpret, we will replace the rownames of the object (containing Ensembl gene IDs) with the gene symbol. Sometimes it happens that there is no gene symbol and in some cases there are multiple genes with the same symbol (see e.g. RGS5). A safe way to handle these cases is to use the <code>uniquifyFeatureNames()</code> function, which will add the Ensembl gene id to symbols where necessary to distinguish between different genes</p> <pre><code>rownames(sce) &lt;- uniquifyFeatureNames(rownames(sce), rowData(sce)$Symbol)\n</code></pre>"},{"location":"episodes/5/#feature-selection","title":"Feature Selection","text":"<p>We often use scRNA-seq data in exploratory analyses to characterize heterogeneity across cells. Procedures like clustering and dimensionality reduction compare cells based on their gene expression profiles, which involves aggregating per-gene differences into a single (dis)similarity metric between every pair of cells. The choice of genes to use in this calculation has a major impact on the behavior of the metric and the performance of downstream methods. We want to select genes that contain useful information about the biology of the system while removing genes that contain random noise. This aims to preserve interesting biological structure without the variance that obscures that structure, and to reduce the size of the data to improve computational efficiency of later steps.</p> <p>The simplest approach to feature selection is to select the most variable genes based on their expression across the population. This assumes that genuine biological differences will manifest as increased variation in the affected genes, compared to other genes that are only affected by technical noise or a baseline level of \u201cuninteresting\u201d biological variation (e.g., from transcriptional bursting). Several methods are available to quantify the variation per gene and to select an appropriate set of highly variable genes (HVGs).</p>"},{"location":"episodes/5/#quantifying-per-gene-variation","title":"Quantifying per-gene variation","text":"<p>Some assays allow the inclusion of known molecules in a known amount covering a wide range, from low to high abundance: spike-ins. The technical noise is assessed based on the amount of spike-ins used, the corresponding read counts obtained and their variation across cells. The variance in expression can then be decomposed into the biological and technical components. There is discussion over whether this step is necessary but like all of the decisions you make in your analyses it would be wise to optimise your parameters and steps over several iterations with a view to existing biological knowlegde and controls.</p> <p>The commonly used UMI-based assays do not (yet?) allow spike-ins. But one can still identify highly variable genes (HVGs), which likely capture biological variation. Assuming that, for most genes, the observed variance across cells is due to technical noise, we can assess technical variation by fitting a trend line between the mean-variance relationship across all genes. Genes that substantially deviate from this trend may then be considered as highly-variable, i.e. capturing biologically interesting variation. The scran function modelGeneVar with carry out this estimation for us.</p> <p>The resulting output gives us a dataframe with all our genes and several columns. It has modeled the mean-variance relationship and from there it has estimated our total variance along with what it considers is the biological and technical variance.</p> <p>code</p> <p><pre><code>gene_var &lt;- modelGeneVar(sce)\n\ngene_var\n</code></pre> <pre><code>gene_var %&gt;% \n  as.data.frame() %&gt;% \n  ggplot(aes(mean, total)) +\n  geom_point() +\n  geom_line(aes(y = tech), colour = \"dodgerblue\", size = 1) +\n  labs(x = \"Mean of log-expression\", y = \"Variance of log-expression\")\n</code></pre> </p>"},{"location":"episodes/5/#selecting-highly-variable-genes","title":"Selecting highly variable genes","text":"<p>Once we have quantified the per-gene variation, the next step is to select the subset of HVGs to use in downstream analyses. A larger subset will reduce the risk of discarding interesting biological signal by retaining more potentially relevant genes, at the cost of increasing noise from irrelevant genes that might obscure said signal. It is difficult to determine the optimal trade-off for any given application as noise in one context may be useful signal in another. </p> <p>Commonly applied strategies are:</p> <ul> <li>take top X genes with largest (biological) variation</li> </ul> <p>Top 1000 genes: <code>getTopHVGs(gene_var, n=1000)</code></p> <p>Top 10% genes: <code>getTopHVGs(gene_var, prop=0.1)</code></p> <ul> <li>based on significance</li> </ul> <p><code>getTopHVGs(gene_var, fdr.threshold = 0.05)</code></p> <ul> <li>keeping all genes above the trend</li> </ul> <p><code>getTopHVGs(gene_var, var.threshold = 0)</code></p> <ul> <li>selecting a priori genes of interest</li> </ul> <p>In our example, we will define \u2018HVGs\u2019 as the top 10% of genes with the highest biological component. This is a fairly arbitrary choice. A common practice is to pick an arbitrary threshold (either based on number of proportion) and proceed with the rest of the analysis, with the intention of testing other choices later, rather than spending much time worrying about obtaining the \u201coptimal\u201d value.</p> <p>code</p> <p><pre><code>hvgs &lt;- getTopHVGs(gene_var, prop=0.1)\nlength(hvgs)\n</code></pre> <pre><code>hvgs[1:10]\n</code></pre> - The result is a vector of gene IDs ordered by their biological variance (i.e. highest deviation from the trend line shown above). We can use this with functions that accept a list of genes as option to restrict their analysis to that subset of genes (e.g. when we do PCA later on).</p> <ul> <li>We can visualise the expression of the top most-variable genes with a violin plot for each gene using the <code>plotExpression()</code> function:</li> </ul> <p><pre><code>plotExpression(sce, features = hvgs[1:20], point_alpha = 0.05)\n</code></pre> </p>"},{"location":"episodes/5/#dimensionality-reduction","title":"Dimensionality Reduction","text":"<p>Many scRNA-seq analysis procedures involve comparing cells based on their expression values across thousands of genes. Thus, each individual gene represents a dimension of the data (and the total number of genes represents the \u201cdimensionality\u201d of the data). More intuitively, if we had a scRNA-seq data set with only two genes, we could visualise our data in a two-dimensional scatterplot, with each axis representing the expression of a gene and each point in the plot representing a cell. Intuitively, we can imagine the same for 3 genes, represented as a 3D plot. Although it becomes harder to imagine, this concept can be extended to data sets with thousands of genes (dimensions), where each cell\u2019s expression profile defines its location in the high-dimensional expression space.</p> <p>As the name suggests, dimensionality reduction aims to reduce the number of separate dimensions in the data. This is possible because different genes are correlated if they are affected by the same biological process. Thus, we do not need to store separate information for individual genes, but can instead compress multiple features into a single dimension, e.g., an \u201ceigengene\u201d (Langfelder and Horvath 2007). This reduces computational work in downstream analyses like clustering, as calculations only need to be performed for a few dimensions, rather than thousands. It also reduces noise by averaging across multiple genes to obtain a more precise representation of the patterns in the data. And finally it enables effective visualisation of the data, for those of us who are not capable of visualizing more than 2 or 3 dimensions.</p> <p>Here, we will cover three methods that are most commonly used in scRNA-seq analysis:</p> <ul> <li>Principal Components Analysis (PCA)</li> <li>t-Distributed Stochastic Neighbor Embedding (t-SNE)</li> <li>Uniform Manifold Approximation and Projection (UMAP)</li> </ul> <p>Before we go into the details of each method, it is important to mention that while the first method (PCA) can be used for downstream analysis of the data (such as cell clustering), the latter two methods (t-SNE and UMAP) should only be used for visualisation and not for any other kind of analysis.</p>"},{"location":"episodes/5/#principal-components-analysis","title":"Principal Components Analysis","text":"<p>One of the most used and well-known methods of dimensionality reduction is principal components analysis (PCA). This method performs a linear transformation of the data, such that a set of variables (genes) are turned into new variables called Principal Components (PCs). These principal components combine information across several genes in a way that best captures the variability observed across samples (cells).</p> <p>Watch this video for more details on how PCA works:</p> <p>After performing a PCA, there is no data loss, i.e. the total number of variables does not change. Only the fraction of variance captured by each variable differs.</p> <p>Each PC represents a dimension in the new expression space. The first PC explains the highest proportion of variance possible. The second PC explains the highest proportion of variance not explained by the first PC. And so on: successive PCs each explain a decreasing amount of variance not captured by the previous ones.</p> <p>The advantage of using PCA is that the total amount of variance explained by the first few PCs is usually enough to capture most of the signal in the data. Therefore, we can exclude the remaining PCs without much loss of information. The stronger the correlation between the initial variables, the stronger the reduction in dimensionality. We will see below how we can choose how many PCs to retain for our downstream analysis.</p>"},{"location":"episodes/5/#running-pca","title":"Running PCA","text":"<p>SingleCellExperiment objects contain a slot that can store representations of our data in reduced dimensions. This is useful as we can keep all the information about our single-cell data within a single object.</p> <p>The <code>runPCA()</code> function can be used to run PCA on a SCE object, and returns an updated version of the single cell object with the PCA result added to the reducedDim slot.</p> <p>Importantly, we can also restrict the PCA to use only some of the features (rows) of the object, which in this case we do by using the highly variable genes we identified earlier.</p> <p>code</p> <pre><code>sce &lt;- runPCA(sce, subset_row = hvgs)\nsce\n</code></pre> <ul> <li>We can see that the output shows a new <code>reducedDimNames</code> value called \u201cPCA\u201d. We can access it by using the <code>reducedDim()</code> function:</li> </ul> <p><pre><code>reducedDim(sce, \"PCA\")[1:10, 1:5]\n</code></pre> By default, <code>runPCA()</code> returns the first 50 PCs, but you can change this number by specifying the <code>ncomponents</code> option.</p> <p>One of the first things to investigate after doing a PCA is how much variance is explained by each PC. This information is stored as an \u201cattribute\u201d (think of it as additional information) attached to the PCA matrix above. The typical way to view this information is using what is known as a \u201cscree plot\u201d.</p> <p><pre><code>percent.var &lt;- attr(reducedDim(sce), \"percentVar\")\nplot(percent.var, log=\"y\", xlab=\"PC\", ylab=\"Variance explained (%)\")\n</code></pre> </p> <ul> <li>We can see how the two first PCs explain a substantial amount of the variance, and very little variation is explained beyond 10-15 PCs. To visualise our cells in the reduced dimension space defined by PC1 and PC2, we can use the<code>plotReducedDim()</code> function.</li> </ul> <p> </p> <ul> <li> <p>The proximity of cells in this plot reflects the similarity of their expression profiles.</p> </li> <li> <p>We can also plot several PCs at once, using the <code>ncomponents</code> option:</p> </li> </ul> <p> </p> <p>Although these plotting functions are useful for quickly visualising our data, more customised visualisations can be used by using the <code>ggcells()</code> function, which extends the regular <code>ggplot()</code> function, but to work directly from the SCE object. We can use it in a similar manner as we use the regular <code>ggplot()</code> function, except we can define aesthetics both from our <code>reducedDim</code> slot as well as <code>colData</code> and even <code>assays</code> (to plot particular gene\u2019s expression). Here is an example, where we facet our plot:</p> <p><pre><code>ggcells(sce, aes(x = PCA.1, y = PCA.2, colour = SampleName)) +\n  geom_point(size = 0.5) +\n  facet_wrap(~ SampleName) +\n  labs(x = \"PC1\", y = \"PC2\", colour = \"Sample\")\n</code></pre> </p>"},{"location":"episodes/5/#pca-diagnostics","title":"PCA Diagnostics","text":"<p>There are a large number of potential confounders, artifacts and biases in scRNA-seq data. One of the main challenges stems from the fact that it is difficult to carry out true technical replication to distinguish biological and technical variability. Here we will continue to explore how experimental artifacts can be identified and removed.</p> <p>One of the ways to achieve this is to calculate the association between our PC scores and different variables associated with our cells such as sample groups, number of detected genes, total reads per cell, percentage of mitochondrial genes, etc. We can achieve this using the <code>getExplanatoryPCs()</code> function (and associated plotting function), which calculates the variance in each PC explained by those variables we choose:</p> <p>code</p> <p><pre><code>explain_pcs &lt;- getExplanatoryPCs(sce,\n                                variables = c(\"sum\",\n                                              \"detected\",\n                                              \"SampleGroup\",\n                                              \"SampleName\",\n                                              \"subsets_Mito_percent\")\n                                )\n\nplotExplanatoryPCs(explain_pcs/100)\n</code></pre> </p> <p>We can see that PC1 can be explained mostly by individual samples (SampleName), mitochondrial expression and mutation group (<code>SampleGroup</code>).</p> <p>We can also compute the marginal R2 for each variable when fitting a linear model regressing expression values for each gene against just that variable, and display a density plot of the gene-wise marginal R2 values for the variables.</p> <p>code</p> <p><pre><code>plotExplanatoryVariables(sce,\n                         variables = c(\n                           \"sum\",\n                           \"detected\",\n                           \"SampleGroup\",\n                           \"SampleName\",\n                           \"subsets_Mito_percent\"\n                         ))\n</code></pre> </p> <p>This analysis indicates that individual and subtype have the highest explanatory power for many genes, and we don\u2019t see technical covariates having as high correlations. If that were the case, we might need to repeat the normalization step while conditioning out for these covariates, or we would include them in downstream analysis.</p>"},{"location":"episodes/5/#choosing-the-number-of-pcs","title":"Choosing the number of PCs","text":"<p>The choice of the number of PCs we retain for downstream analyses is a decision that is analogous to the choice of the number of HVGs to use. Using more PCs will retain more biological signal at the cost of including more noise that might mask said signal. Much like the choice of the number of HVGs, it is hard to determine whether an \u201coptimal\u201d choice exists for the number of PCs. Even if we put aside the technical variation that is almost always uninteresting, there is no straightforward way to automatically determine which aspects of biological variation are relevant; one analyst\u2019s biological signal may be irrelevant noise to another analyst with a different scientific question.</p> <p>Most practitioners will simply set the number of PCs to a \u201creasonable\u201d but arbitrary value, typically ranging from 10 to 50. This is often satisfactory as the later PCs explain so little variance that their inclusion or omission has no major effect. For example, in our dataset, few PCs explain more than 1% of the variance in the entire dataset.</p> <p>code</p> <pre><code>table(percent.var &gt; 1)\n</code></pre> <p>The most commonly used strategies to choose PCs for downstream analysis include:</p> <ul> <li>selecting the top X PCs (with X typically ranging from 10 to 50)</li> <li>using the elbow point in the scree plot</li> <li>using technical noise</li> <li>using permutation</li> </ul>"},{"location":"episodes/5/#elbow-point","title":"Elbow Point","text":"<p>To choose the elbow point in our scree plot, we can use the following:</p> <p>code</p> <pre><code>chosen_elbow &lt;- findElbowPoint(percent.var)\nchosen_elbow\n</code></pre> <ul> <li>Here is our scree plot again, but this time with a vertical line indicating the elbow point:</li> </ul> <p><pre><code>plot(percent.var)\nabline(v=chosen_elbow, col=\"dodgerblue\")\n</code></pre> </p> Alternatives to the elbow point method: denoising PCA and permutation"},{"location":"episodes/5/#denoising-pca","title":"Denoising PCA","text":"<p>The assumption of this method is that the biology drives most of the variance and hence should be captured by the first few PCs, while technical noise affects each gene independently, hence it should be captured by later PCs. Therefore, our aim in this approach is to find the minimum number of PCs that explains more variance than the total technical variance across genes (estimated from our mean-variance trend).</p> <p>code</p> <p>This method is implemented in the <code>denoisePCA()</code> function:</p> <pre><code>sce.denoised &lt;- denoisePCA(sce, technical = gene_var)\n</code></pre> <p>If we look at our PCA result, we can see that it has 6 columns.</p> <pre><code>ncol(reducedDim(sce.denoised, \"PCA\"))\n</code></pre>"},{"location":"episodes/5/#permutation","title":"Permutation","text":"<p>We do not demonstrate this method, as it is more code intensive. The idea is to permute (or \u201cshuffle\u201d) a subset of the data, rerun the PCA and calculate the percentage of variance explained by each PC on this \u201crandom\u201d dataset. We can then compare the observed variance explained in the original data with this null or random expectation and determine a cutoff where the observed variance explained drops to similar values as the variance explained in the shuffled data.</p> <p> In this example (which is for illustration only) we may define a threshold at PC8, since after that the variance explained in the observed data drops below the levels in the permuted (randomised) data. </p>"},{"location":"episodes/5/#t-sne-t-distributed-stochastic-neighbor-embedding","title":"t-SNE: t-Distributed Stochastic Neighbor Embedding","text":"<p>The t-Distributed Stochastic Neighbor Embedding (t-SNE) approach addresses the main shortcoming of PCA, which is that it can only capture linear transformations of the original variables (genes). Instead, t-SNE allows for non-linear transformations, while preserving the local structure of the data. This means that neighbourhoods of similar samples (cells, in our case) will appear together in a t-SNE projection, with distinct cell clusters separating from each other.</p> <p>As you can see below, compared to PCA we get much tighter clusters of samples, with more structure in the data captured by two t-SNE axis, compared to the two first principal components.</p> <p> </p> <p>We will not go into the details of the algorithm here, but briefly it involves two main steps:</p> <ul> <li> <p>Calculating a similarity matrix between every pair of samples. This similarity is scaled by a Normal distribution, such that points that are far away from each other are \u201cpenalised\u201d with a very low similarity score. The variance of this normal distribution can be thought of as a \u201cneighbourhood\u201d size when computing similarities between cells, and is parameterised by a term called perplexity.</p> </li> <li> <p>Then, samples are projected on a low-dimensional space (usually two dimensions) such that the similarities between the points in this new space are as close as possible to the similarities in the original high-dimensional space. This step involves a stochastic algorithm that \u201cmoves\u201d the points around until it converges on a stable solution. In this case, the similarity between samples is scaled by a t-distribution (that\u2019s where the \u201ct\u201d in \u201ct-SNE\u201d comes from), which is used instead of the Normal to guarantee that points within a cluster are still distinguishable from each other in the 2D-plane (the t-distribution has \u201cfatter\u201d tails than the Normal distribution).</p> </li> </ul> <p>Watch this video to learn more about how t-SNE works:</p> <p>There are two important points to remember:</p> <ul> <li>the perplexity parameter, which indicates the relative importance of the local and global patterns in the structure of the data set. The default value in the functions we will use is 50, but different values should be tested to ensure consistency in the results.</li> <li>stochasticity: because the t-SNE algorithm is stochastic, running the analysis multiple times will produce slightly different results each time (unless we set a \u201cseed\u201d for the random number generator).</li> </ul> <p>See this interactive article on \u201cHow to Use t-SNE Effectively\u201d, which illustrates how changing these parameters can lead to widely different results.</p> <p>Importantly, because of the non-linear nature of this algorithm, strong interpretations based on how distant different groups of cells are from each other on a t-SNE plot are discouraged, as they are not necessarily meaningful. This is why it is often the case that the x- and y-axis scales are omitted from these plots (as in the example above), as they are largely uninterpretable. Therefore, the results of a t-SNE projection should be used for visualisation only and not for downstream analysis (such as cell clustering).</p>"},{"location":"episodes/5/#running-t-sne","title":"Running t-SNE","text":"<p>Similarly to how we did with PCA, there are functions that can run a t-SNE directly on our SingleCellExperiment object. We will leave this exploration for you to do in the following exercises, but the basic code is very similar to that used with PCA. For example, the following would run t-SNE with default options:</p> <p>code</p> <p><pre><code>sce &lt;- runTSNE(sce)\n</code></pre> <pre><code>plotTSNE(sce, colour_by = \"SampleName\")\n</code></pre> </p> <p>One thing to note here is that, because of the computational demands of this algorithm, the general practice is to run it on the PCA results rather than on the full matrix of normalised counts. The reason is that, as we\u2019ve seen earlier, the first few PCs should capture most of the biologically meaningful variance in the data, thus reducing the influence of technical noise in our analysis, as well as substantially reducing the computational time to run the analysis.</p>"},{"location":"episodes/5/#umap-uniform-manifold-approximation-and-projection","title":"UMAP: Uniform Manifold Approximation and Projection","text":"<p>Simiarly to t-SNE, UMAP performs a non-linear transformation of the data to project it down to lower dimensions. One difference to t-SNE is that this method claims to preserve both local and global structures (i.e. the relative positions of clusters are, most of the times, meaningful). However, it is worth mentioning that there is some debate as to whether this is always the case, as is explored in this recent paper by Chari, Banerjee and Pachter (2021).</p> <p>Compared to t-SNE, the UMAP visualization tends to have more compact visual clusters with more empty space between them. It also attempts to preserve more of the global structure than t -SNE. From a practical perspective, UMAP is much faster than t-SNE, which may be an important consideration for large datasets.</p> <p>Similarly to t-SNE, since this is a non-linear method of dimensionality reduction, the results of a UMAP projection should be used for visualisation only and not for downstream analysis (such as cell clustering).</p>"},{"location":"episodes/5/#running-umap","title":"Running UMAP","text":"<p>code</p> <p>Running UMAP is very similar to what we\u2019ve seen already for PCA and t-SNE, only the function name changes:</p> <p><pre><code>set.seed(123)\nsce &lt;- runUMAP(sce)\n</code></pre> <pre><code>plotUMAP(sce, colour_by = \"SampleName\")\n</code></pre> </p> <p>Because this UMAP also involves a series of randomization steps, setting the random-generator seed (as we did above) is critical if we want to obtain reproducible results after each run.</p> <p>Like t-SNE, UMAP has its own suite of hyperparameters that affect the visualization. Of these, the number of neighbors (n_neighbors) and the minimum distance between embedded points (min_dist) have the greatest effect on the granularity of the output. If these values are too low, random noise will be incorrectly treated as high-resolution structure, while values that are too high will discard fine structure altogether in favor of obtaining an accurate overview of the entire dataset. Again, it is a good idea to test a range of values for these parameters to ensure that they do not compromise any conclusions drawn from a UMAP plot.</p> <p>See this interactive article that goes into more depth about the underlying methods, and explores the impacts of changing the n_neighbours and min_dist parameters: Understanding UMAP.</p> <p>Similarly to what we did with t-SNE, we will explore this further in the following exercise.</p> <p>Exercise - fill in the missing lines of following code</p> <ul> <li>Our main objectives are:<ul> <li>Add a UMAP projection of the data to our SCE object</li> <li>Explore how the main tuneable parameter of the algorithm - neighbourhood size - affects the results</li> <li>Compare how UMAP compares to t-SNE in terms of revealing structure in the data</li> </ul> </li> </ul> code <pre><code># Run UMAP ----\n\n# Part A\n# run the UMAP with 50 neighbours\nset.seed(123) # set seed for reproducibility\nsce &lt;- runUMAP(sce, \n               name = \"UMAP_neighbors50\",\n               dimred = \"PCA\",\n               FIXME)\n\n# Part B\n# visualise the resulting UMAP projection (colour cells by sample)\n\n\n# Part C\n# run the UMAP with 5 and 500 neighbours and compare the results\n\n\n# Part D\n# compare the UMAP projection with the t-SNE projections \n# would you prefer one over the other?\n</code></pre> Hint <ul> <li>Check out the ?runUMAP help page, there should be an argument for fixing the number of nearest neighbours.</li> <li>You can use the same code as for plotting the TSNE but replacing the arguments to display the UMAP output data.</li> <li>Change the number of neighbours argument in the runUMAP() function to see what changes.</li> <li>Redraw the TSNE and compare it with your UMAP.</li> </ul> Answer <pre><code># Run UMAP ----\n\n# run the UMAP with 50 neighbours\nset.seed(123) # set seed for reproducibility\nsce &lt;- runUMAP(sce, \n               name = \"UMAP_neighbors50\",\n               dimred = \"PCA\",\n               n_neighbors = 50)\n\n# visualise the resulting UMAP projection\n# colour cells by sample\nggcells(sce, aes(x = UMAP_neighbors50.1, y = UMAP_neighbors50.2, \n                 colour = SampleName)) +\n  geom_point()\n\n# run the UMAP with 5 and 500 neighbours and compare the results\nset.seed(123) # set seed for reproducibility\nsce &lt;- runUMAP(sce, \n               name = \"UMAP_neighbors5\",\n               dimred = \"PCA\",\n               n_neighbors = 5)\nsce &lt;- runUMAP(sce, \n               name = \"UMAP_neighbors500\",\n               dimred = \"PCA\",\n               n_neighbors = 500)\n\nggcells(sce, aes(x = UMAP_neighbors5.1, y = UMAP_neighbors5.2, \n                 colour = SampleName)) +\n  geom_point() +\n  labs(title = \"Neighbours = 5\")\nggcells(sce, aes(x = UMAP_neighbors500.1, y = UMAP_neighbors500.2, \n                 colour = SampleName)) +\n  geom_point() +\n  labs(title = \"Neighbours = 500\")\n\n# compare the UMAP projection with the t-SNE projections \n# would you prefer one over the other?\nsce &lt;- runTSNE(sce, perplexity = 50, name=\"TSNE_perplex50\")\n\nggcells(sce, aes(x = TSNE_perplex50.1, y = TSNE_perplex50.2, \n                 colour = SampleName)) +\n  geom_point()\nggcells(sce, aes(x = UMAP_neighbors50.1, y = UMAP_neighbors50.2, \n                 colour = SampleName)) +\n  geom_point()\n</code></pre>"},{"location":"episodes/5/#save-sce-object","title":"Save SCE object","text":"<p>Optionally, we can save our object, which now contains our dimensionality reduction analysis in it. This is useful as it will save time next time we pick up on our analysis.</p> <p>code</p> <pre><code>saveRDS(sce, \"R_objects/caron_dimRed.Rds\")\n</code></pre>"},{"location":"episodes/6/","title":"6. Batch correction and data set integration","text":"<p>Often, single-cell experiments are done by processing samples in multiple batches. This may be related to logistical constraints such as the inability to run all experimental conditions in parallel, or more extreme cases where samples are processed in different laboratories, by different people and even sequenced with different technologies (e.g. samples from human patients collected in different hospitals). These differences across sample batches very often result in global gene expression differences across those batches. Since batch-to-batch transcriptomic differences are likely unrelated to biological differences, we would ideally want \u201cremove\u201d them before drawing inferences about our cell populations.</p> <p>Biases due to batch effects are not new to single-cell RNA-seq. Indeed, several methods have been previously developed for standard bulk RNA-seq approaches. Some of those approaches rely on linear models that \u201cregress out\u201d the batch effect, assuming that the cell composition is similar across batches. However, in single-cell RNA-seq we may very often expect changes in cell compositions across batches (e.g. in our course data we have data from cancer samples such as ETV6-RUNX as well as a reference panel of healthy blood cells, PBMMCs). Therefore, methods are necessary that can deal with with heterogeneity across batches.</p> <p>In recent years, several methods have been developed to deal with this challenge (too many to list here!). Some of the most popular ones include the Mutual Nearest Neighbours (MNN) algorithm, a Principal Components Analysis-based clustering method implemented in the package HARMONY and a method that combines Canonical Correlation Analysis (CCC) and MNN implemented in the package Seurat 3. These methods have been shown to perform well in several benchmark studies (e.g. Luecken et al 2022 and Tran et al 2020), although one important message from these studies is that no single method is universally the best in all situations. For example, some methods may be better at preserving small populations of cells as separate groups in the integrated data at the cost of poorer overall integration, while others may be better at removing batch effects at the cost of also removing some biological signal.</p> <p>In this section we will apply the Mutual Nearest Neighbours (MNN) algorithm, which is readily available to use with the `SingleCellExperiment`` object we\u2019ve been working with so far. However, other methods can be applied to the data in a similar manner (each package may use a slightly different syntax, but they mostly start with either a matrix of counts or a PCA projection). Therefore, what we will explore in this section - visualisation of the integrated data, looking at mixture of cell populations, etc. - can be done with those other methods as well.</p>"},{"location":"episodes/6/#example-data-set-pbmmc_1-technical-replicates","title":"Example data set - PBMMC_1 technical replicates","text":"<p>To demonstrate the integration process, we will use two samples from the Caron dataset that will illustrate the purposes of dataset integration with batch correction. One is the PBMMC_1 sample that we have already seen, the other is a technical replicate derived from the same sample material (we will use our previous SCE object in a later exercise).</p> <p>Whilst the two samples come from distinct 10X runs they are derived from the same starting material and therefore, if there was no batch effect, they should be identical. These samples have been processed as discussed up until this point in the course:</p> <ul> <li>Raw counts were imported from the cellranger output folder (using <code>DropletUtils::read10xCounts()</code>).</li> <li>Basic quality filtering was performed in each batch to remove cells that were outliers for total counts, number of detected genes and high percentage of mitochondrial counts (using <code>scuttle::quickPerCellQC()</code>).</li> <li>Reads were log-normalised using the deconvolution method (using <code>scuttle::computePooledFactors()</code>).</li> </ul> <p>We already have the necessary objects prepared, and load them for this session:</p> <p>code</p> <p><pre><code>library(scater)\nlibrary(scran)\nlibrary(batchelor)\nlibrary(bluster)\nlibrary(pheatmap)\nlibrary(magrittr)\n</code></pre> <pre><code>sce_rep1 &lt;- readRDS(\"R_objects/PBMMC_1a_dimRed.rds\")\nsce_rep2 &lt;- readRDS(\"R_objects/PBMMC_1b_dimRed.rds\")\n</code></pre></p> <ul> <li>First we should add information about which technical replicate each sample is. This is added as a new column in the colData DataFrame of the object.</li> </ul> <pre><code>colData(sce_rep1)$batch &lt;- \"1\"\ncolData(sce_rep2)$batch &lt;- \"2\"\n</code></pre>"},{"location":"episodes/6/#data-preparation","title":"Data Preparation","text":"<p>Before the data integration step, we need to prepare our data (we will later see how we can run all these steps with a single function, but it is good to see all the steps individually).</p> <ol> <li>First we need to fit a mean-variance model to each data set separately (using <code>scran::modelGeneVar()</code>). This will be used later to identify highly-variable genes (HVGs) in each batch.</li> <li>Subset our objects to only include the set of genes that are common in both samples (in case different genes were filtered out).</li> <li>Rescale the batches to account for different sequencing depths. We had previously log-normalised the counts in each batch. However, this did not take into account differences in total sequencing depth across different batches. This step therefore helps to bring the different batches to a \u201csimilar scale\u201d, which helps with the data integration step.</li> <li>Select variable genes (feature selection), by averaging the variance previously estimated in each batch separately. This will gives us genes that are highly variable across both batches.</li> </ol> <p>Fit mean-variance mode to each data set</p> <pre><code>gene_var_rep1 &lt;- modelGeneVar(sce_rep1)\ngene_var_rep2 &lt;- modelGeneVar(sce_rep2)\n</code></pre> <p>Identify common genes and subset both the sce objects and the mean-variance model objects</p> <p>The two samples have been QC\u2019d and filtered independently. Removing undetected genes from each set independently has results in slightly different genes being retained in each dataset: <pre><code>nrow(sce_rep1)\n</code></pre> <pre><code>nrow(sce_rep2)\n</code></pre> <pre><code>sum(rowData(sce_rep1)$ID%in%rowData(sce_rep2)$ID)\n</code></pre> <pre><code>common_genes &lt;- intersect(rownames(sce_rep1), rownames(sce_rep2))\n</code></pre></p> <ul> <li>Subset the SCE object</li> </ul> <pre><code>sce_rep1 &lt;- sce_rep1[common_genes, ]\nsce_rep2 &lt;- sce_rep2[common_genes, ]\n</code></pre> <ul> <li>Subset the mean-variance results</li> </ul> <pre><code>gene_var_rep1 &lt;- gene_var_rep1[common_genes, ]\ngene_var_rep2 &lt;- gene_var_rep2[common_genes, ]\n</code></pre> <p>Rescale and combine data</p> <pre><code>rescaled_sces &lt;- multiBatchNorm(sce_rep1, sce_rep2)\n\nsce &lt;- cbind(rescaled_sces[[1]], \n             rescaled_sces[[2]])\n</code></pre> <p>Combine gene variance models and identify HVGs</p> <pre><code>gene_var_combined &lt;- combineVar(gene_var_rep1, gene_var_rep2)\n\nhvgs &lt;- gene_var_combined$bio &gt; 0\nsum(hvgs)\n</code></pre>"},{"location":"episodes/6/#visualising-uncorrected-data","title":"Visualising Uncorrected Data","text":"<p>Before running the data integration procedure, it is always good to check how much of a problem the batch effect might be. This is typically done by visualising the combined data in a reduced dimensionality projection such as t-SNE or UMAP.</p> <p>Another strategy to check for batch effects, involves clustering the cells (we will cover cell clustering in detail later) and checking whether both batches are represented in each cluster. If clusters contain cells from only one of the clusters, this may indicate a batch effect is present.</p> <p>code</p> <p><pre><code>sce &lt;- runPCA(sce, subset_row = hvgs)\n\nsce$cluster_uncorrected &lt;- clusterCells(sce, use.dimred = \"PCA\")\n\nsce &lt;- runTSNE(sce, dimred = \"PCA\", name = \"TSNE_uncorrected\")\n\nplotReducedDim(sce, dimred = \"TSNE_uncorrected\",\n               colour_by = \"batch\",\n               text_by = \"cluster_uncorrected\")\n\nplotReducedDim(sce, dimred = \"PCA\",\n           colour_by = \"batch\",\n           text_by = \"cluster_uncorrected\")               \n</code></pre> </p> <ul> <li>We can also assess cluster occupancy data as a table. <pre><code>table(Cluster = sce$cluster_uncorrected, Batch = sce$batch)\n</code></pre></li> </ul> <p>As we can see from the t-SNE, cells seem to somewhat separate according to batch (although distinct groups of cells are still visible at a more global scale).</p> <p>We can also see that some of the clusters identified in the data contain an unbalanced number of cells from each batch.</p> <p>However, from the t-SNE, there is some suggestion that these could be the same cell type. Another example is cluster 7, which contains cells from both batches, but on the t-SNE there is still some within-batch separation of these cells (if we formed sub-clusters they would likely separate by batch).</p> <p>It is worth noting that, although this suggests a batch effect (and in the case of technical replicates this is a good assumption), there might be cases where there are genuine differences in cell populations across batches (e.g. if the different batches represent samples from different tissues).</p> <p>Data integration algorithms designed for single-cell RNA-seq do allow for unique cell types existing across batches, however, it\u2019s always good to check the results of the integration using independent information (e.g. prior information about genes that are specific to particular cell types).</p>"},{"location":"episodes/6/#correct-the-data-mutual-nearest-neighbour-mnn","title":"Correct the data - Mutual Nearest Neighbour (MNN)","text":"<p>The Mutual Nearest Neighbours (MNN) algorithm works by determining if pairs of cells from two different batches are within the top K closest neighbours of each other.</p> <p>Schematic of the MNN algorithm  - Reference: Haghverdi et al 2018</p> <p>Here are the assumptions of this approach (taken from Haghverdi et al 2018):</p> <ol> <li>There is at least one cell population that is present in both batches,</li> <li>The batch effect is almost orthogonal [i.e. uncorrelated] to the biological subspace</li> <li>The batch-effect variation is much smaller than the biological-effect variation between different cell types</li> </ol> <p></p> <p>We will use the `fastMNN()`` function. We will need to provide the following:</p> <ul> <li>The SCE object(s) with the log-normalised counts to correct.</li> <li>`batch`` - A variable specifying the batch labels for each cell (usually we include that information as a column in the colData slot of the object).</li> <li>`d`` - The number of dimensions to use from a PCA projection of the data (the method uses PCA values for computational efficiency - and it has also been shown to often perform better than using the full matrix of logcounts).</li> <li><code>k</code> - The number of cells to consider when calculating the mutual nearest neighbours between each pair of cells.</li> <li>`subset.row`` - The genes to use for the PCA step of the algorithm. We use the highly-variable genes determined earlier from the pooled mean-variance model.</li> </ul> <pre><code>mnn_corrected &lt;- fastMNN(sce, \n                         batch = sce$batch,\n                         d = 50,\n                         k = 20, \n                         subset.row = hvgs)\nmnn_corrected\n</code></pre> <p>The result of the function is a new <code>SingleCellExperiment</code> object with a \u201ccorrected\u201d matrix in the reducedDims slot, containing corrected low-dimensional coordinates for each cell. This \u201ccorrected\u201d matrix can be used in downstream analyses such as clustering.</p> <p>The new object also contains a \u201creconstructed\u201d matrix in the assays slot. This can be viewed as per-gene corrected log-expression values, but should not be used for any quantitative analyses as the magnitude and even the direction of differences in expression between cells may not have been preserved.</p> <p>We can add the \u201ccorrected\u201d matrix to our original SCE object, so that we keep all the data together in the same object.</p> <pre><code>reducedDim(sce, \"corrected\") &lt;- reducedDim(mnn_corrected, \"corrected\")\n</code></pre> How many neighbours (k) should we consider? <p>The answer to this question - as is often the case in bioinformatics! - is that this will depend on the dataset. One heuristic to use is to think about what is the minimum number a given cell type that you expect to be shared between the batches. For example, the value <code>k = 20</code> is approximately equivalent to assuming that we expect there to be a group of a least 20 cells of one type in one batch that have an equivalent group of 20 or more cells of the same type in the other batch.</p> <p>Sometimes, based on the analysis of known cell-specific marker genes, we may notice that some batch-specific clusters should have been merged, but are not. In those cases, increasing the number of k neighbours will result in a stronger integration (we are effectively increasing the chance that a given pair of cells are mutual neighbours of each other).</p>"},{"location":"episodes/6/#visualising-the-corrected-data","title":"Visualising the Corrected Data","text":"<p>Now that we have batch corrected the data, we can visualise the impact of this using a tSNE as we did for the uncorrected data.</p> <p><pre><code>sce$cluster_corrected &lt;- clusterCells(sce, use.dimred = \"corrected\")\n\nsce &lt;- runTSNE(sce, dimred = \"corrected\", name = \"TSNE_corrected\")\n\nplotReducedDim(sce, \n               dimred = \"TSNE_corrected\", \n               colour_by = \"batch\", \n               text_by = \"cluster_corrected\")\n</code></pre> </p> <p>From this new t-SNE, we can see that the cells from the two batches seem to be much better mixed with each other. There is still some apparent separation, which could indicate that we should use a higher value of k with <code>fastMNN()</code>, or could be real biological differences between the samples. If in doubt, it may be better to avoid over-correcting the data, and rather to come back to the analysis after we did some more investigation of what kind of genes separate those cells (a topic for the next session).</p> <p>We can also compare the mixing of cells in the clusters before and after correction.</p> <p>We can confirm from this visualisation that there is more mixing of cells within a batch in the corrected data compared to the original one.</p> Uncorrected batchesCorrected batches <p><pre><code>data.frame(Cluster = sce$cluster_corrected, Batch = sce$batch) %&gt;%\n  ggplot(aes(x = Cluster)) +\n    geom_bar(aes(fill = Batch), position = \"fill\") +\n    labs(title = \"MNN-uncorrected data\") +\n  scale_y_continuous(labels = scales::percent)\n</code></pre> </p> <p><pre><code>data.frame(Cluster = sce$cluster_corrected, Batch = sce$batch) %&gt;%\n  ggplot(aes(x = Cluster)) +\n    geom_bar(aes(fill = Batch), position = \"fill\") +\n    labs(title = \"MNN-corrected data\") +\n  scale_y_continuous(labels = scales::percent)\n</code></pre> </p>"},{"location":"episodes/6/#the-quickcorrect-function","title":"The <code>quickCorrect()</code> function","text":"<p>The <code>batchelor</code> package has made the data integration procedure easier by having a wrapper function called <code>quickCorrect``, which automates the individual steps we went through to prepare the data before MNN correction. This includes intersecting the batches for common genes, log-normalising the batches, and identifying highly variable genes across batches. By default,</code>quickCorrect` will use the fastMNN method, but you can change it to use other correction algorithms by modifying the PARAM argument (see more details in the function\u2019s help page).</p> <p>Let\u2019s visualise the results to check that it is similar to what we obtained previously.</p> <p><pre><code>sce_quick_mnn &lt;- quickCorrect(sce_rep1, sce_rep2)$corrected\n</code></pre> <pre><code>sce_quick_mnn$batch &lt;- factor(sce_quick_mnn$batch)\nsce_quick_mnn %&gt;%\n  runTSNE(dimred = \"corrected\") %&gt;%\n  plotTSNE(colour_by = \"batch\")\n</code></pre></p> <p></p>"},{"location":"episodes/6/#multiple-batches","title":"Multiple batches","text":"<p>The above example used only two samples (batches), but it will often be the case that we have many samples or batches. It is straightforward to simultaneously perform correction across &gt;2 batches with <code>quickCorrect()</code>, either by using the batch= option or by providing several separate `SingleCellExperiment`` objects. Lets try this out with all of the samples from the Caron dataset.</p> <p>Exercise</p> <p>In this exercise we will work with a <code>SingleCellExperiment</code> that contains the 11 samples that we have worked with so far.</p> <p>This object has been processed as discussed in the previous sections, but we down-sampled the data to 500 cells per sample for processing speed (in real analysis you would not do this).</p> <p>Load the data: <pre><code>sce_all &lt;- readRDS(\"R_objects/Caron_dimRed.500.rds\")\n</code></pre></p> <p>You should then add the rest of the code in order to:</p> <ol> <li>Batch correct the data using the quickCorrect() wrapper, treating each individual sample as a batch. See the Help page (?quickCorrect) for details on how to specify batch when only providing one single cell experiment object.</li> <li>Add the \u201ccorrected\u201d matrix from the new object into the \u201creducedDim\u201d slot of the original single cell experiment object</li> <li>Plot a tSNE of your corrected data and compare it to the uncorrected data.</li> </ol> <p>Note that the object we have loaded already contains a tSNE computed from the uncorrected logcounts (in the default reducedDim slot called \u201ctSNE\u201d).</p> Answer <p>code</p> <p><pre><code># obtain a batch-corrected SCE object\nsce_all_corrected &lt;- quickCorrect(sce_all, batch = sce_all$SampleName)$corrected\n\n# add the corrected matrix to the original object - to keep it all together\nreducedDim(sce_all, \"corrected\") &lt;- reducedDim(sce_all_corrected, \"corrected\")\n\n#  add a tSNE using the corrected data\nset.seed(323)\nsce_all &lt;- runTSNE(sce_all, \n                   dimred = \"corrected\",\n                   name = \"TSNE_corrected\")\n\n# visualise both corrected and uncorrected\nplotReducedDim(sce_all, dimred = \"TSNE\", colour_by = \"SampleName\")\n</code></pre> <pre><code>plotReducedDim(sce_all, dimred = \"TSNE_corrected\", colour_by = \"SampleName\")\n</code></pre></p> Specifics of multiple batch correction: merge order"},{"location":"episodes/6/#specifying-merge-order","title":"Specifying merge order","text":"<p>During the batch correction, batches are merged in a pairwise manner. If we have more than two batches, first two batches are merged to create a new cohort, then the next batch is merged with this new cohort, and so on until all batches have been integrated. The order is which this is done by default is the order in which the batches are provided to the command.</p> <p>Batch correction will work more effectively between batches with large number of cells and between batches that have many cells of the same cell type. As a result it is often beneficial to specify the order in which batches should be combined. If we are expecting differences in cell populations present between different sample groups it is probably advisable to integrate replicates within sample groups first, and then integrate the different sample groups.</p> <p>This can be specified using the merge.order argument of <code>fastMNN</code>. This, and any other <code>fastMNN</code> arguments you wish to control such as <code>d</code> or <code>k</code>, can be provided to <code>quickCorrect``` using it\u2019s</code>Param = FastMnnParam()` argument.</p> <p>The merge.order argument should be provided a nested list object that determines the merge order. Please see the fastMNN help page for a detailed explanation of how this can be constructed. In short, each batch within a list will be merged (in the order provided) before batches in different lists are merged.</p> <p>In our case, we have four sample groups: ETV6-RUNX1, HHD, PBMMC, PRE-T. We might decide that it makes sense to integrate replicates from the same sample group before integrating between sample groups. To do this we want to integrate the samples in the following order</p> <p>In our case, we have four sample groups: ETV6-RUNX1, HHD, PBMMC, PRE-T. We might decide that it makes sense to integrate replicates from the same sample group before integrating between sample groups. To do this we want to integrate the samples in the following order</p> <ol> <li> <p>ETV6-RUNX1_1 + ETV6-RUNX1_2 \u2192 + ETV6-RUNX1_3 \u2192 + ETV6-RUNX1_4 \u2192 ETV6-RUNX1_batch</p> <ol> <li>HHD_1 + HHD_2 \u2192 HHD_batch</li> </ol> </li> <li> <p>PBMMC_1 &amp; PBMMC_2 \u2192 + PBMMC_3 \u2192 PBMMC_batch</p> </li> <li> <p>PRE-T_1 + PRE-T_2 \u2192 PRE-T_batch  </p> </li> <li> <p>ETV6-RUNX1_batch + HHD_batch -&gt;  + PBMMC_batch \u2192 + T_batch \u2192 Integrated_data_set</p> </li> </ol> <p>!!! note \"\"</p> <p>To do this we need a nested list that looks like this:</p> <p><code>bash    list(     list(\"ETV6-RUNX1_1\", \"ETV6-RUNX1_2\", \"ETV6-RUNX1_3\", \"ETV6-RUNX1_4\"),     list(\"HHD_1\", \"HHD_2\"),     list(\"PBMMC_1\", \"PBMMC_2\", \"PBMMC_3\"),     list(\"PRE-T_1\", \"PRE-T_2\")     )</code>     !!! r-project-2 \"So, to apply this we would use the following:\"</p> <pre><code>    ```r\n    sce_all &lt;- readRDS(\"R_objects/Caron_dimRed.500.rds\")\n   table(sce_all$SampleName)\n   merge_order &lt;- list(\n             list(\"ETV6-RUNX1_1\", \"ETV6-RUNX1_2\", \"ETV6-RUNX1_3\", \"ETV6-RUNX1_4\"),\n             list(\"HHD_1\", \"HHD_2\"),\n             list(\"PBMMC_1\", \"PBMMC_2\", \"PBMMC_3\"),\n             list(\"PRE-T_1\", \"PRE-T_2\")\n                      )\n\n   sce_all_corrected &lt;- quickCorrect(sce_all,\n                                     batch = sce_all$SampleName,\n                                      PARAM = FastMnnParam(merge.order = merge_order)\n                                      )$corrected\n\n    # add the corrected matrix to the original object - to keep it all together\n    reducedDim(sce_all, \"corrected_mo\") &lt;- reducedDim(sce_all_corrected, \"corrected\")\n\n    #  add a tSNE using the corrected data\n    set.seed(323)\n    sce_all &lt;- runTSNE(sce_all, \n                       dimred = \"corrected_mo\",\n                       name = \"TSNE_corrected_mo\")\n    ```\n    !!! note \"\"\n    &lt;br&gt;\n\n    === \"Uncorrected TSNE\"\n        ```r\n       plotReducedDim(sce_all, dimred = \"TSNE\", colour_by = \"SampleName\")\n        ```\n        ![image](../r_images/46-batchcorrect-uncorrectedTSNE.png)\n\n    === \"Corrected TSNE - default merge order\"\n\n        ```r\n       plotReducedDim(sce_all, dimred = \"TSNE_corrected\", colour_by = \"SampleName\")\n       ```\n       ![image](../r_images/47-batchcorrect-correctedTSNE-defaultmerge.png)\n\n   === \"Corrected TSNE - merger by sample group\"\n\n        ```r\n        plotReducedDim(sce_all, dimred = \"TSNE_corrected_mo\", colour_by = \"SampleName\")\n        ```\n        ![image](../r_images/48-batchcorrect-correctedTSNE-mergeby-samplegroup.png)\n</code></pre>"},{"location":"episodes/6/#correction-diagnostics","title":"Correction Diagnostics","text":""},{"location":"episodes/6/#mixing-between-batches-bar-plots","title":"Mixing Between Batches - Bar plots","text":"<p>As before, we can explore our data to see if clustering the cells using the corrected data results in batches containing cells from multiple samples/batches, rather than being skewed to having one-batch-per-cluster.</p> <p>This clustering serves as a proxy for the population structure. So, if the batch effect is successfully corrected, clusters corresponding to shared cell types or states should contain cells from multiple batches.</p> Uncorrected batchesCorrected batches <p><pre><code>sce_all$cluster_uncorrected &lt;- clusterCells(sce_all, use.dimred = \"PCA\")\n\ndata.frame(Cluster = sce_all$cluster_uncorrected, Sample = sce_all$SampleName) %&gt;%\n  ggplot(aes(x = Cluster)) +\n    geom_bar(aes(fill = Sample), position = \"fill\") +\n    labs(title = \"MNN-uncorrected data\") +\n  scale_y_continuous(labels = scales::percent)\n</code></pre> </p> <p><pre><code>sce_all$cluster_corrected &lt;- clusterCells(sce_all, use.dimred = \"corrected\")\n\ndata.frame(Cluster = sce_all$cluster_corrected, Sample = sce_all$SampleName) %&gt;%\n  ggplot(aes(x = Cluster)) +\n    geom_bar(aes(fill = Sample), position = \"fill\") +\n    labs(title = \"MNN-corrected data\") +\n  scale_y_continuous(labels = scales::percent)\n</code></pre> </p>"},{"location":"episodes/6/#mixing-between-batches-variance-of-batch-abundancies-in-clusters","title":"Mixing Between Batches - variance of batch abundancies in clusters","text":"<p>One approach to assess the degree of mixing between clusters is to calculate the variance in the log-normalized cell abundances across batches for each cluster. A high variance value in this case represents a cluster with unequal representation of cells from each batch. Therefore, those clusters with the highest variance values may be due to incomplete correction. Alternatively, these may be due to true biological differences between batches (which could be investigated, for example, by looking at the expression of known cell-type-specific genes).</p> <p>code</p> <ul> <li>This is a qualitative, exploratory method to diagnose issues with batch correction. As we can see from this table, this is a good indication of clusters with an extreme imbalance of cells from different clusters, but we can see that there is a limitation in making strong conclusions from clusters that have an overall low number of cells. <pre><code>cluster_var &lt;- clusterAbundanceVar(sce_all$cluster_corrected, \n                                   batch = sce_all$SampleName)\n\nbatch_per_cluster &lt;- table(Cluster = sce_all$cluster_corrected, \n                           Batch = sce_all$SampleName)\n\nbatch_per_cluster[order(cluster_var, decreasing = TRUE), ]\n</code></pre></li> </ul>"},{"location":"episodes/6/#preserving-biological-heterogeneity","title":"Preserving Biological Heterogeneity","text":"<p>Another useful diagnostic check is to compare the pre-correction clustering of each batch to the clustering of the same cells in the corrected data. Accurate data integration should preserve population structure within each batch as there is no batch effect to remove between cells in the same batch. This check complements the previously mentioned diagnostics that only focus on the removal of differences between batches. Specifically, it protects us against scenarios where the correction method simply aggregates all cells together, which would achieve perfect mixing but also discard the biological heterogeneity of interest. Lets go back to our simple two sample example to look at some of the ways we can investigate.</p> <p>code</p> <p><pre><code>table(colLabels(sce_rep1))\n</code></pre> <pre><code>table(colLabels(sce_rep2))\n</code></pre></p>"},{"location":"episodes/6/#nesting-of-before-and-after-correction-clusters","title":"Nesting of before and after correction clusters","text":"<p>Ideally, we should see a many-to-1 mapping where the post-correction clustering is nested inside the pre-correction clustering. This indicates that any within-batch structure was preserved after correction while acknowledging that greater resolution is possible with more cells. We quantify this mapping using the nestedClusters() function from the bluster package, which identifies the nesting of post-correction clusters within the pre-correction clusters. Well-nested clusters have high max values, indicating that most of their cells are derived from a single pre-correction cluster.</p> <p>code</p> <p><pre><code>original_clusters &lt;- colLabels(sce_rep1)\ncorrected_clusters_rep1 &lt;- sce[,colnames(sce_rep1)]$cluster_corrected\ntab &lt;- nestedClusters(ref=paste(\"before\", original_clusters),\n                      alt=paste(\"after\", corrected_clusters_rep1))\n\ntab$alt.mapping\n</code></pre> </p> <p>We can visualize this mapping for the samples</p> <p><pre><code>pheatmap(tab$proportions, \n         cluster_row=FALSE, \n         cluster_col=FALSE,\n         main=\"Sample 1 comparison\")\n</code></pre> </p> Rand index"},{"location":"episodes/6/#adjusted-rand-index","title":"Adjusted Rand index","text":"<p>We can use the adjusted Rand index to quantify the agreement between the clusterings before and after batch correction. The adjusted Rand index gives us a measure of the proportion of pairs of cells that have the same relative status in both clusterings - i.e. they were are in the same cluster in both clusterings or they are in different clusters in both clusterings, as opposed to, for example, being in the same cluster in one clustering and different clusters in the other.</p> <p>Larger indices are more desirable as this indicates that within-batch heterogeneity is preserved, though this must be balanced against the ability of each method to actually perform batch correction.</p> <p>code</p> <p><pre><code>pairwiseRand(corrected_clusters_rep1, colLabels(sce_rep1), mode=\"index\")\npairwiseRand(corrected_clusters_rep2, colLabels(sce_rep2), mode=\"index\")\n</code></pre> <pre><code>tab &lt;- pairwiseRand(colLabels(sce_rep1), corrected_clusters_rep1)\npheatmap(tab, \n         cluster_row=FALSE, \n         cluster_col=FALSE,\n         main=\"Sample 1 probabilities\")\n</code></pre> </p> <p>code</p> <p><pre><code>tab &lt;- pairwiseRand(colLabels(sce_rep2), corrected_clusters_rep2)\n\npheatmap(tab, \n         cluster_row=FALSE, \n         cluster_col=FALSE,\n         main=\"Sample 2 probabilities\")\n</code></pre> </p>"},{"location":"episodes/6/#mnn-specific-test","title":"MNN specific test","text":"<p>For fastMNN(), one useful diagnostic is the proportion of variance within each batch that is lost during MNN correction. Specifically, this refers to the within-batch variance that is removed during orthogonalization with respect to the average correction vector at each merge step. This is returned via the lost.var field in the metadata of mnn.out, which contains a matrix of the variance lost in each batch (column) at each merge step (row).</p> <p>code</p> <pre><code>metadata(sce_quick_mnn)$merge.info$lost.var\n</code></pre> <p>Large proportions of lost variance (&gt;10%) suggest that correction is removing genuine biological heterogeneity. This would occur due to violations of the assumption of orthogonality between the batch effect and the biological subspace (Haghverdi et al. 2018). In this case, the proportion of lost variance is smaller, indicating that non-orthogonality is not to much of a major concern</p>"},{"location":"episodes/7/","title":"7. Clustering","text":"<p>Once we have normalized the data and removed confounders we can carry out analyses that are relevant to the biological questions at hand. The exact nature of the analysis depends on the data set. One of the most promising applications of scRNA-seq is de novo discovery and annotation of cell-types based on transcription profiles. This requires the identification of groups of cells based on the similarities of the transcriptomes without any prior knowledge of the label a.k.a. unsupervised clustering. To avoid the challenges caused by the noise and high dimensionality of the scRNA-seq data, clustering is performed after feature selection and dimensionality reduction. For data that has not required batch correction this would usually be based on the PCA output. As our data has required batch correction we will use the \u201ccorrected\u201d reducedDims data.</p> <p>We will focus here on graph-based clustering, however, it is also possible to apply hierarchical clustering and k-means clustering on smaller data sets</p> <p>We will use the data set generated in the previous session. This contains 7 samples from the Caron data set. In the interests of time, each sample has been downsampled to only contain 500 cells.</p> <p><pre><code>library(scater)\nlibrary(scran)\nlibrary(bluster)\nlibrary(cluster)\nlibrary(igraph)\nlibrary(pheatmap)\nlibrary(patchwork)\nlibrary(tidyverse)\n</code></pre> <pre><code>sce &lt;- readRDS(\"R_objects/Caron_batch_corrected.500.rds\")\n</code></pre> <pre><code>table(sce$SampleName)\n</code></pre></p>"},{"location":"episodes/7/#introduction-to-graph-based-clustering","title":"Introduction to Graph-based clustering","text":"<p>Graph-based clustering entails building a nearest-neighbour (NN) graph using cells as nodes and their similarity as edges, then identifying \u2018communities\u2019 of cells within the network. A graph-based clustering method has three key parameters:</p> <ul> <li>How many neighbors are considered when constructing the graph</li> <li>What scheme is used to weight the edges</li> <li>Which community detection algorithm is used to define the clusters</li> </ul>"},{"location":"episodes/7/#connecting-nodes-cells-based-on-nearest-neighbours","title":"Connecting nodes (cells) based on nearest neighbours","text":"<p>Two types of NN graph may be used: \u201cK nearest-neighbour\u201d (KNN) and \u201cshared nearest-neighbour\u201d (SNN). In a KNN graph, two nodes (cells), say A and B, are connected by an edge if the distance between them is amongst the k smallest distances from A to other cells. In an SNN graph A and B are connected if the distance is amongst the k samllest distances from A to other cells and also among the k smallest distance from B to other cells.</p> <p></p> <p>In the figure above, if k is 5, then A and B would be connected in a KNN graph as B is one of the 5 closest cells to A, however, they would not be connected in an SNN graph as B has 5 other cells that are closer to it than A.</p> <p>The value of k can be roughly interpreted as the anticipated size of the smallest subpopulation\u201d (see <code>scran</code>\u2019s <code>buildSNNGraph()</code> manual).</p> <p>The plot below shows the same data set as a network built using three different numbers of neighbours: 5, 15 and 25 (from here).</p> <p></p>"},{"location":"episodes/7/#weighting-the-edges","title":"Weighting the edges","text":"<p>The edges between nodes (cells) can be weighted based on the similarity of the cells; edges connecting cells that are more closely related will have a higher weight. The three common methods for this weighting are (see the bluster package documentation for the makeSNNGraph function):</p> <ul> <li>rank - the weight is based on the highest rank of the shared nearest neighbours</li> <li>number - the weight is based the number of nearest neighbours in common between the two cells</li> <li>jaccard - the Jaccard index of the two cells\u2019 sets of nearest neighbours.</li> </ul>"},{"location":"episodes/7/#grouping-nodes-cells-into-clusters","title":"Grouping nodes (cells) into clusters","text":"<p>Clusters are identified using an algorithm that interprets the connections of the graph to find groups of highly interconnected cells. A variety of different algorithms are available to do this, in these materials we will focus on three methods: walktrap, louvain and leiden. See the OSCA book for details of others available in scran.</p>"},{"location":"episodes/7/#modularity","title":"Modularity","text":"<p>Several methods to detect clusters (\u2018communities\u2019) in networks rely on a metric called \u201cmodularity\u201d. For a given partition of cells into clusters, modularity measures how separated clusters are from each other, based on the difference between the observed and expected weight of edges between nodes. For the whole graph, the closer to 1 the better.</p>"},{"location":"episodes/7/#pros-and-cons-of-graph-based-clustering","title":"Pros and Cons of graph based clustering","text":"<ul> <li> <p>Pros:</p> <ul> <li>fast and memory efficient (avoids the need to construct a distance matrix for all pairs of cells)</li> <li>no assumptions on the shape of the clusters or the distribution of cells within each cluster</li> <li>no need to specify a number of clusters to identify (but the size of the neighbourhood used affects the size of clusters)</li> </ul> </li> <li> <p>Cons:</p> <ul> <li>loss of information beyond neighboring cells, which can affect community detection in regions with many cells.</li> </ul> </li> </ul>"},{"location":"episodes/7/#implementation","title":"Implementation","text":"<p>The implementation of clustering in R is carried out using functions from a number of different packages, in particular the bluster and igraph packages. scran provides a handy \u201cwrapper\u201d function <code>clusterCells</code> that allows us use a variety of different algorithms with one simple command.</p> <p>By default <code>clusterCells</code> just returns a vector containing the cluster number for each cell. We can also retrieve the intermediate statistics (varying according to the algorithm used) and the SNN graph by specifying the bluster argument <code>full = TRUE</code>. If you are only interested in retrieving the clusters, this isn\u2019t necessary but in this first instance we will retrieve the graph and visualise it. The default algorithm for clusterCells is Walktrap with k is set to 10 by default. The default edge weighting is \u201crank\u201d.</p> <p>code</p> <p><pre><code>clustering1 &lt;- clusterCells(sce, use.dimred=\"corrected\", full=TRUE)\nThis has defined 24 clusters with varying numbers of cells:\n</code></pre> <pre><code>table(clustering1$clusters)\n</code></pre></p> <p>The number of cells in the data set is large and plotting all the cells would take too long, so we randomly choose 1000 nodes (cells) in the network before plotting the resulting smaller network. Adding sample data to the graph and plotting the results are done using the igraph package. Cells can be color-coded by sample type:</p> <p><pre><code># extract the graph\nsnn.gr &lt;- clustering1$objects$graph\n\n# Add Sample group to vertices (nodes, ie cells)\nV(snn.gr)$SampleGroup &lt;- as.character(colData(sce)$SampleGroup)\n\n# pick 1000 nodes randomly\nset.seed(1423)\nselectedNodes &lt;- sample(3500, 1000)\n\n# subset graph for these 1000 randomly chosen nodes\nsnn.gr.subset &lt;- subgraph(snn.gr, selectedNodes)\n\n# set colors for clusters\ngrps &lt;-  V(snn.gr.subset)$SampleGroup\ncols &lt;- c(\"dodgerblue\", \"lightyellow\")[as.numeric(factor(grps))]\nnames(cols) &lt;- grps\n\n# plot graph\nplot.igraph(snn.gr.subset,\n  layout = layout_with_fr(snn.gr.subset),\n  vertex.size = 3, \n  vertex.label = NA,\n  vertex.color = cols,\n  frame.color = cols,\n  main = \"default parameters\"\n)\n\n# add legend\nlegend('bottomright',\n       legend=unique(names(cols)),\n       pch=21,\n       pt.bg=unique(cols),\n       pt.cex=1, cex=.6, bty=\"n\", ncol=1)\n</code></pre> </p> <p>More commonly we will visualise the clusters by superimposing them on a t-SNE or UMAP plot. We can store the clusters in the sce object colData.</p> <p><pre><code>sce$Clusters1 &lt;- clustering1$clusters\nplotReducedDim(sce, \n               dimred = \"TSNE_corrected\",\n               colour_by=\"Clusters1\",\n               text_by = \"Clusters1\")\n</code></pre> </p>"},{"location":"episodes/7/#the-walktrap-method","title":"The Walktrap method","text":"<p>The walktrap method relies on short random walks (a few steps) through the network. These walks tend to be \u2018trapped\u2019 in highly-connected regions of the network. Node similarity is measured based on these walks. Nodes are first each assigned their own community. Pairwise distances are computed and the two closest communities are grouped. These steps are repeated a given number of times to produce a dendrogram. Hierarchical clustering is then applied to the distance matrix. The best partition is that with the highest modularity. The original article describing the algorithm is Pons P, Latapy M (2006) Computing communities in large networks using random walks. J Graph Algorithms Appl 10(2):191\u2013218</p> <p>Walktrap is the default algorithm for <code>clusterCells</code>, k is set to 10 by default and the default edge weighting is \u201crank\u201d. To explicitly request a specific algorithm and to set the k to a different number of nearest neighbours, we use a <code>SNNGraphParam</code> object from the bluster package (which is the package clusterCells is using under the hood).</p> <p>Let\u2019s set the k to 15 but keep the other parameters the same. This time we will just return the clusters:</p> <p>code</p> <pre><code>sce$walktrap15 &lt;- clusterCells(sce, \n                           use.dimred = \"corrected\", \n                           BLUSPARAM = SNNGraphParam(k = 15, \n                                                     cluster.fun = \"walktrap\"))\n</code></pre> <ul> <li>This time we have defined 16 clustering. As a general rule, increasing k will tend to decrease the number of clusters (not always, but generally).</li> </ul> <pre><code>table(sce$walktrap15)\n</code></pre> <ul> <li>We can visualise the assignment of cells from different samples to the clusters using a heatmap. This gives us an overview of how well each cluster is represented across the samples and the replicates. Several clusters (2, 8, 9 and 16) are present in the PBMMC samples, but absent from the ETV6_RUNX1 samples for instance.</li> </ul> <p><pre><code>w15_table &lt;- log(table(sce$walktrap15, sce$SampleName)+1)\npheatmap(w15_table, cluster_rows = TRUE, cluster_cols = FALSE)\n</code></pre> </p> <p>Most clusters comprise cells from several replicates of the same sample type, cluster 10 appears to be predominantly cells from the ETV6-RUNX samples.</p> <p>We can visualise this on the TSNE:</p> <p><pre><code>plotReducedDim(sce, \n               dimred = \"TSNE_corrected\",\n               colour_by=\"walktrap15\", \n               text_by = \"walktrap15\")\n</code></pre> </p> <pre><code>plotReducedDim(sce, \n               dimred = \"TSNE_corrected\",\n               colour_by=\"walktrap15\", \n               text_by = \"walktrap15\",\n               other_fields = list(\"SampleGroup\")) +\n  facet_wrap(vars(SampleGroup))\n</code></pre> <p></p>"},{"location":"episodes/7/#the-louvain-method","title":"The Louvain method","text":"<p>With the Louvain method, nodes are also first assigned their own community. This hierarchical agglomerative method then progresses in two-step iterations:</p> <ol> <li>nodes are re-assigned one at a time to the community for which they increase modularity the most, if at all.</li> <li>a new, \u2018aggregate\u2019 network is built where nodes are the communities formed in the previous step.</li> </ol> <p>These two steps are repeated until modularity stops increasing. The diagram below is copied from this article.</p> <p> Louvain algorithm. The Louvain algorithm starts from a singleton partition in which each node is in its own community (a). The algorithm moves individual nodes from one community to another to find a partition (b). Based on this partition, an aggregate network is created \u00a9. The algorithm then moves individual nodes in the aggregate network (d). These steps are repeated until the quality cannot be increased further. </p> <p>We now apply the Louvain approach, store its outcome in the SCE object and show cluster sizes.</p> <p><pre><code>sce$louvain15 &lt;- clusterCells(sce, \n                           use.dimred = \"corrected\", \n                           BLUSPARAM = SNNGraphParam(k = 15, \n                                                     cluster.fun = \"louvain\"))\n</code></pre> <pre><code>table(sce$louvain15)\n</code></pre> </p> <p>If we split by sample type we can see differences in the clusters between the sample groups:</p> <p><pre><code>plotReducedDim(sce, \n               dimred = \"TSNE_corrected\",\n               colour_by=\"louvain15\", \n               text_by = \"louvain15\",\n               other_fields = list(\"SampleGroup\")) +\n   facet_wrap(vars(SampleGroup)) \n</code></pre> </p>"},{"location":"episodes/7/#the-leiden-method","title":"The Leiden method","text":"<p>The Leiden method improves on the Louvain method by guaranteeing that at each iteration clusters are connected and well-separated. The method includes an extra step in the iterations: after nodes are moved (step 1), the resulting partition is refined (step2) and only then the new aggregate network made, and refined (step 3). The diagram below is copied from this article.</p> <p> Leiden algorithm. The Leiden algorithm starts from a singleton partition (a). The algorithm moves individual nodes from one community to another to find a partition (b), which is then refined \u00a9. An aggregate network (d) is created based on the refined partition, using the non-refined partition to create an initial partition for the aggregate network. For example, the red community in (b) is refined into two subcommunities in \u00a9, which after aggregation become two separate nodes in (d), both belonging to the same community. The algorithm then moves individual nodes in the aggregate network (e). In this case, refinement does not change the partition (f). These steps are repeated until no further improvements can be made. </p> <p>Exercise</p> <p>run the clustering again, this time using the \u201cleiden\u201d method.</p> <ul> <li> <p>Set the k to 20 and add the results of the clustering to the<code>sce</code> object in a new column called \u201cleiden20\u201d.</p> </li> <li> <p>How many clusters does this result in?</p> </li> <li> <p>Visualize the clusters by plotting the t-SNE with the cells coloured according to your new clustering.</p> </li> </ul> Answer <p>code</p> <ul> <li> <p>First run the clustering with `clusterCells:`` <pre><code>sce$leiden20 &lt;- clusterCells(sce, \n                           use.dimred = \"corrected\", \n                           BLUSPARAM = SNNGraphParam(k = 20, \n                                                     cluster.fun = \"leiden\"))\n</code></pre></p> </li> <li> <p>We can quickly look at the results by summarising using <code>table</code>. <pre><code>table(sce$leiden20)\n</code></pre></p> </li> <li> <p>There are 15 clusters, although cluster 7 contains only 3 cells and cluster 8 contains only 1 cell. The t-SNE plot shows cells color-coded by cluster membership: <pre><code>plotReducedDim(sce, \n               dimred = \"TSNE_corrected\",\n               colour_by = \"leiden20\", \n               text_by = \"leiden20\")\n</code></pre></p> </li> </ul>"},{"location":"episodes/7/#assessing-cluster-behaviour","title":"Assessing cluster behaviour","text":"<p>A variety of metrics are available to aid us in assessing the behaviour of a particular clustering method on our data. These can help us in assessing how well defined different clusters within a single clustering are in terms of the relatedness of cells within the cluster and the how well separated that cluster is from cells in other clusters, and to compare the results of different clustering methods or parameter values (e.g. different values for k).</p> <p>We will consider \u201cSilhouette width\u201d and \u201cModularity\u201d. </p>"},{"location":"episodes/7/#silhouette-width","title":"Silhouette width","text":"<p>The silhouette width (so named after the look of the traditional graph for plotting the results) is a measure of how closely related cells within cluster are to one another versus how closely related cells in the cluster are to cells in other clusters. This allows us to assess cluster separation.</p> <p>For each cell in the cluster we calculate the the average distance to all other cells in the cluster and the average distance to all cells not in the cluster. The cells silhouette width is the difference between these divided by the maximum of the two values. Cells with a large silhouette are strongly related to cells in the cluster, cells with a negative silhouette width are more closely related to other clusters.</p> <p>We will use the `approxSilhouette`` function from the bluster package. The resulting table gives us the silhouette width for each cell, the cluster it belongs to, and which other cluster it is most closely related to.</p> <p>code</p> <p><pre><code>sil.approx &lt;- approxSilhouette(reducedDim(sce, \"corrected\"),\n                               clusters=sce$leiden20)\n</code></pre> <pre><code>sil.approx\n</code></pre> <pre><code>SCALEFUN &lt;- scale_fill_manual\n</code></pre></p> <p><pre><code>plotSilBeeswarm &lt;- function(silDat){\n  silTab &lt;- silDat %&gt;% \n    as.data.frame() %&gt;% \n    mutate(closestCluster = ifelse(width &gt; 0, cluster, other) %&gt;% factor())\n\n  plt &lt;- silTab %&gt;% \n      ggplot(aes(x=cluster, y=width, colour=closestCluster)) +\n        ggbeeswarm::geom_quasirandom(method=\"smiley\", alpha=0.6) +\n        theme_bw()\n\n  plt &lt;- scater:::.resolve_plot_colours(plt, silTab$closestCluster, \"closestCluster\")\n  plt\n}\n\np1 &lt;- plotSilBeeswarm(sil.approx)\np2 &lt;- plotReducedDim(sce, \n                     dimred = \"TSNE_corrected\", \n                     colour_by=\"leiden20\", \n                     text_by = \"leiden20\")\np1 + p2\n</code></pre> </p> We could also look at the correspondence between different clusters by plotting these numbers on a grid showing for each cluster number of cells in that cluster that are closer to another cluster, colouring each tile by the proportion of the total cells in the cluster that it contains. Ideally we would like to see a strong diagonal band and only a few off-diagonal tiles containing small number of cells. <p><pre><code>plotSilGrid &lt;- function(silDat){\n  silDat %&gt;% \n    as.data.frame() %&gt;% \n    mutate(closestCluster = ifelse(width &gt; 0, cluster, other) %&gt;% factor()) %&gt;% \n    count(cluster, closestCluster,  name=\"olap\") %&gt;% \n    group_by(cluster) %&gt;% \n    mutate(total  = sum(olap)) %&gt;% \n    mutate(proportion = olap / total) %&gt;% \n    mutate(proportion = ifelse(cluster == closestCluster, proportion, -proportion)) %&gt;% \n    ggplot(aes(x = cluster, y = closestCluster)) +\n      geom_tile(aes(fill = proportion)) +\n      geom_text(aes(label = olap), size=5) +\n      scale_fill_gradientn(colors = c(\"#fc8d59\", \"#ffffbf\", \"#91cf60\"),\n                            limits = c(-1, 1)) +\n      geom_vline(xintercept=seq(0.5, 30.5, by=1)) +\n      geom_hline(yintercept=seq(0.5, 30.5, by=1), colour=\"lightgrey\", linetype=2) +\n      guides(fill = \"none\") +\n      theme(\n          aspect.ratio = 1,\n          panel.background = element_blank())\n}\nplotSilGrid(sil.approx)\n</code></pre> </p> From above plots we can see that clusters 7, 8 and 12 appear to have a good degree of separation, however, clusters 7 and 8 only contains few cells, whilst there are many cells in other clusters that appear closer to them than they are to their assigned cluster. Perhaps clusters 7 and 8 needs to be merged with cluster 1. Let\u2019s do the same plots with the walktrap clusters generated with k=15. <p><pre><code>sil.approx &lt;- approxSilhouette(reducedDim(sce, \"corrected\"),\n                               clusters=sce$walktrap15)\n\nwp1 &lt;- plotSilBeeswarm(sil.approx)\n\nwp2 &lt;- plotReducedDim(sce, \n                     dimred = \"TSNE_corrected\", \n                     colour_by=\"walktrap15\", \n                     text_by = \"walktrap15\")\n\nwp3 &lt;- plotSilGrid(sil.approx)\n\nwp1 + wp2 + wp3\n</code></pre> </p> This clustering appears to have generated a set of clusters with slightly better separatedness than the Leiden method with a k of 20. And again with the louvain clusters: <p><pre><code>sil.approx &lt;- approxSilhouette(reducedDim(sce, \"corrected\"),\n                               clusters=sce$louvain15)\n\nlp1 &lt;- plotSilBeeswarm(sil.approx)\n\nlp2 &lt;- plotReducedDim(sce, \n                     dimred = \"TSNE_corrected\", \n                     colour_by=\"louvain15\", \n                     text_by = \"louvain15\")\n\nlp3 &lt;- plotSilGrid(sil.approx)\n\nlp1 + lp2 + lp3\n</code></pre> </p>"},{"location":"episodes/7/#modularity-to-assess-cluster-quality","title":"Modularity to assess cluster quality","text":"<p>As mentioned earlier, the modularity metric is used in evaluating the separatedness of clusters. Some of the clustering algorithms, e.g. Louvain, seek to optimise this for the entire NN graph as part of their cluster detection. Modularity is a ratio between the observed weights of the edges within a cluster versus the expected weights if the edges were randomly distributed between all nodes. Rather than calculating a single modularity value for the whole graph, we can instead calculate a pair-wise modularity value between each pair of clusters using the pairwiseModularity function from the bluster package. For this we need to have the graph from the clustering, so we will rerun the walktrap clustering with k=15 to obtain this. We can plot the resulting ratios on a heatmap. We would expect the highest modularity values to be on the diagonal.</p> <p>code</p> <p><pre><code>walktrap15 &lt;- clusterCells(sce, \n                           use.dimred = \"corrected\", \n                           BLUSPARAM = SNNGraphParam(k = 15, \n                                                     cluster.fun = \"walktrap\"),\n                           full = TRUE)\ng &lt;- walktrap15$objects$graph\nratio &lt;- pairwiseModularity(g, walktrap15$clusters, as.ratio=TRUE)\n\nhm1 &lt;- pheatmap(log2(ratio+1),\n         cluster_rows=FALSE, \n         cluster_cols=FALSE,\n         color=colorRampPalette(c(\"white\", \"blue\"))(100))\n</code></pre> </p> <ul> <li>We can compare this to the silhouette width grid</li> </ul> <p><pre><code>wp4 &lt;- ggplotify::as.ggplot(hm1)\nwp2 + wp3 + wp4\n</code></pre> </p> <ul> <li>Largely, this reflects what we saw from the silhouette widths, but also reveals some additional inter-connectedness between other clusters. We can also visualise this as network graph where nodes are clusters and the edge weights are the modularity.</li> </ul> <p><pre><code>cluster.gr &lt;- igraph::graph_from_adjacency_matrix(log2(ratio+1),\n                                                  mode=\"upper\", \n                                                  weighted=TRUE, diag=FALSE)\n\nset.seed(11001010)\nplot(cluster.gr, \n     edge.width=igraph::E(cluster.gr)$weight*5,\n     layout=igraph::layout_with_lgl)\n</code></pre> </p>"},{"location":"episodes/7/#comparing-two-sets-of-clusters","title":"Comparing two sets of clusters","text":"<p>We can assess the concordance between different clustering methods to get a better idea of how they eachtreat the data, e.g. does one cluster from one method equate to just one cluster in the other or is it a combination of different clusters. This may be revealing about the underlying biology. We will use the Jaccard index as measure of concordance between clusters. A value of 1 represents perfect concordance between clusters (i.e. they contain exactly the same cells).</p> <p>code</p> <p><pre><code>jacc.mat &lt;- linkClustersMatrix(sce$louvain15, sce$walktrap15)\nrownames(jacc.mat) &lt;- paste(\"Louvain\", rownames(jacc.mat))\ncolnames(jacc.mat) &lt;- paste(\"Walktrap\", colnames(jacc.mat))\npheatmap(jacc.mat, color=viridis::viridis(100), cluster_cols=FALSE, cluster_rows=FALSE)\n</code></pre> </p> <p>We can see that Louvain clusters 2, 6, 7, and 9 are equivalent to walktrap clusters 14, 7, 12, and 11 respectively. The remaining Louvain clusters are combinations of cells from various walktrap clusters. We may want to look at marker genes for these clusters to assess what these two different views are telling us about the biology.</p>"},{"location":"episodes/8/","title":"8. Identification of cluster marker genes","text":"<p>In order to aid the interpretation of the clustering results that we covered in the previous section, it is helpful to identify genes that contribute to the separation of cells into those clusters.</p> <p>The main approach to achieve this, is to identify genes that are differently expressed between clusters. These may be, for example, exclusively expressed in a single cluster or perhaps differentiate between a few different clusters. There are different methods to identify expression differences between clusters: using mean expression level, or the ranking of the gene by its expression, or the proportions of cells that express the gene.</p> <p>Our main objective in this section is to cover some of the methods that can be used to achieve this goal, and obtain a summary table of results</p> <p>Setup</p> <pre><code>library(scater)\nlibrary(scran)\nlibrary(tidyverse)\nlibrary(patchwork)\n</code></pre> <ul> <li>We will use the data set generated in the clustering session. This contains 7 samples from the Caron data set. For the purposes of these materials, in the interests of time, each sample has been downsampled to only contain 500 cells.</li> <li>read single cell object</li> </ul> <p><pre><code>sce &lt;- readRDS(\"R_objects/Caron_clustered.500.rds\")\n</code></pre> <pre><code>rownames(sce)[11:20]\n</code></pre> <pre><code>all(sce$k.25_cluster.fun.leiden == sce$label)\n</code></pre></p> <ul> <li> <p>To remind ourselves, we can visualise the clusters on a UMAP: <pre><code>plotReducedDim(sce, \n               dimred = \"UMAP_corrected\",\n               colour_by = \"label\", \n               text_by = \"label\")\n</code></pre> </p> </li> <li> <p>Our objective is to identify genes that distinguish these clusters from one another - \u201ccluster marker genes\u201d. Intuitively we hope that the clusters relate to specific cell populations, and therefore we are trying to find genes that will allow us to identify the cell types for each cluster.</p> </li> <li> <p>For example genes such as the \u201cCST3\u201d gene, which is a known monocyte marker:</p> </li> </ul> <p><pre><code>plotReducedDim(sce, \n               dimred = \"UMAP_corrected\",\n               colour_by = \"CST3\", \n               text_by = \"label\", \n               by_exprs_values = \"reconstructed\",\n               add_legend = FALSE)\n</code></pre> </p>"},{"location":"episodes/8/#identifying-cluster-marker-genes","title":"Identifying cluster marker genes","text":"<p>Although we have defined our clusters based on the batch-corrected expression values, these should not be used for for gene-based analyses like marker gene detection. Instead, we should use the uncorrected (normalised) expression values for differential expression between clusters. This is because data integration algorithms bring cells together based on their overall gene expression, but for each gene individually the data transformation may introduce artificial agreement between batches, which is not ideal for gene-level differential analysis. Furthermore, the severity of these biases is dependent on the parameters used for data integration (such as the number of nearest neighbours in the `fastMNN()`` method).</p> <p>Valid assays to use in gene based differential analysis tests are the normalised counts obtained from the deconvolution method (using <code>scuttle::computePooledFactors() + scuttle::logNormCounts()</code>) or from the variance stabilising transformation method (using <code>sctransform::vst()</code>. In our SCE object, we have the normalised counts in the \u201clogcounts\u201d assay, which we can access with <code>assay(sce, \"logcounts\")</code> (or by using the shortcut <code>logcounts(sce)</code>).</p>"},{"location":"episodes/8/#paiwise-cluster-comparisons","title":"Paiwise Cluster Comparisons","text":"<p>The basic approach for marker gene identification across clusters is to perform statistical tests for each gene between every pair of clusters. The scoreMarkers() function can do this for us, while accounting for known factors (aka \u201cblocking factors\u201d or \u201cblocks\u201d), such as sample batch.</p> <p>The <code>scoreMarkers()</code> function outputs a list of DataFrame objects, one for each cluster compared to all others. However, note that the blocking assumes that each pair of clusters is present in at least one of the blocks. If there are two clusters which are not both present in at least one block (in our case Samples), then that pairwise comparison will by necessity be omitted.</p> <p>By default the <code>scoreMarkers()</code> function will use the log-normalised counts as stored in the \u201clogcounts\u201d assay slot of the single cell object, so there is no need for us to specify it.</p> <ul> <li>calculate pairwise marker gene statistics</li> </ul> <pre><code>markers &lt;- scoreMarkers(sce, \n                        groups = sce$label, \n                        block = sce$SampleName)\n</code></pre> <p>The returned object is a list of the same length as the number of clusters. We can access the results for a particular cluster thus:</p> <ul> <li>extract results for cluster 11</li> </ul> <pre><code>c11_markers &lt;- as.data.frame(markers[[\"11\"]])\nhead(c11_markers)\n</code></pre> This DataFrame contains the results for cluster 10. The first four columns contain summary statistics: <ul> <li>self.average - the mean log-expression in the cluster of interest</li> <li>other.average - the grand mean across all other clusters</li> <li>self.detected - the proportion of cells with detected expression in the cluster of interest</li> <li>other.detected - the mean detected proportion across all other clusters.</li> </ul> The remaining columns contain summaries of three scores from the pairwise comparisons. The three scores are: <ul> <li>logFC.cohen - \u201cCohen\u2019s d\u201d - this is the log fold change of mean gene expression standardized by the average standard deviation across the groups. This can be interpreted in a similar way to log fold change in that a positive value indicates upregulation in the cluster of interest.</li> <li>AUC - \u201cArea Under the Curve\u201d - this quantifies the ability to distinguish between two gene expression distributions. It can be interpreted as the likelihood that any random cell in the cluster of interest will have a higher expression of the gene than any random cell in the other cluster. It ranges from 0 to 1, where 1 can be interpreted as upregulation, 0 downregulation, and 0.5 as no difference.</li> <li>logFC.detected - this is the log fold change in the proportion of cells in which the gene is detected in the cluster of interest, versus the proportion of cells in which the gene is detected in the other cluster. Positive values indicate that the gene is detected in more cells in the cluster of interest than the other cluster. Note, this takes no account of the magnitude of the gene expression, instead this metric helps to identify presence/absence differences in gene expression between clusters.</li> </ul>"},{"location":"episodes/8/#heatmap-of-marker-genes","title":"Heatmap of marker genes","text":"<p>We have already seen how we can use the plotExpression() function to visualise the distribution of expression in our data between clusters. We have also seen how to use plotReducedDim() to visualise a gene\u2019s expression on the projected reduced dimensionality space.</p> <p>Another useful type of visualisation is to use heatmaps to show the expression of these genes of interest. We will demonstrate this using the top marker genes for cluster 11.</p> <p>Get top-ranked markers for cluster 11</p> <pre><code>c11_top_genes &lt;- c11_markers %&gt;% \n  filter(rank.logFC.cohen &lt;= 5) %&gt;% \n  rownames()\n</code></pre> <p>Visualise their expression as a heatmap</p> <p><pre><code>plotHeatmap(sce, \n            features = c11_top_genes,\n            order_columns_by = c(\"label\", \"SampleGroup\"))\n</code></pre> </p> <p>Alternatively, we can summarise the expression across sample goups and generate a heatmap showing the average expression across cells within each group using the function plotGroupedHeatmap(). We can specify any factors causing batch effects using the block arguments and the batch effects will be regressed out of the averages.</p> <ul> <li>heatmap average per group (cluster)</li> </ul> <p><pre><code>plotGroupedHeatmap(sce, \n                   features = c11_top_genes,\n                   group = \"label\",\n                   block = \"SampleGroup\")\n</code></pre> </p> <p>In both cases, the colour scale of expression is showing the logcounts in their original scale. However, for this kind of visualisation, it may sometimes be useful to scale the data (aka Z-score), which brings all the genes to the same relative scale.</p> <p><pre><code># scaled heatmap (z-scores)\nplotHeatmap(sce, \n            features = c11_top_genes,\n            order_columns_by = c(\"label\", \"SampleGroup\"),\n            scale = TRUE, \n            center = TRUE,\n            zlim = c(-3, 3))\n</code></pre> </p> <p><pre><code>plotGroupedHeatmap(sce, \n                   features = c11_top_genes,\n                   group = \"label\",\n                   block = \"SampleGroup\",\n                   scale = TRUE, \n                   center = TRUE,\n                   zlim = c(-3, 3))\n</code></pre> </p> <p>In this case, the colour scale can be interpreted as the number of standard deviations above/below the mean of that gene across all cells.</p> <p>Another useful visualisation is to use dot plots of expression that show both the average gene expression (as a colour scale) and the number of cells in which the gene is detected (as the size of the points). We can generate such a plot using the plotDots() function:</p> <p>code</p> <p><pre><code># dot plot of expression showing average expression and detection rate\nplotDots(sce, \n         features = c11_top_genes,\n         group = \"label\", \n         block = \"SampleGroup\",\n         scale = TRUE, center = TRUE, zlim = c(-3, 3))\n</code></pre> </p>"},{"location":"episodes/8/#adjusting-the-log-fold-change","title":"Adjusting the log-fold change","text":"<p>The AUC and Cohen\u2019s d scores incorporate both the gene expression differences between the clusters and the variance in gene expression scores within each cluster. If a gene has low variance, it is possible that it will be ranked highly even if the magnitude of the difference between the clusters is low. These genes will not necessarily make good marker genes. It may therefore be desirable to favour the detection of genes with larger log-fold changes.</p> <p>For example, in the results from cluster 11, the gene SNX10 had a min-rank for Cohen\u2019s d of 5:</p> <p>code</p> <pre><code>c11_markers[\"SNX10\", ] %&gt;% \n  dplyr::select(min.logFC.cohen, max.logFC.cohen, rank.logFC.cohen)\n</code></pre> <p>However, we can also see that its LFC goes from 0.3 to 7, which is a large range. Looking at its expression, we can see what might be going on:</p> <p><pre><code>plotExpression(sce,\n               features = \"SNX10\",\n               x = \"label\")\n</code></pre> </p> <p>This gene has very low variation in expression in some clusters (because it\u2019s lowly detected), and because Cohen\u2019s d measures average differences scaled by variance, the gene comes up as having a high value for that metric in some comparisons.</p> <p>To make our analysis more restrictive, we can instead indicate to the <code>scoreMarkers()</code> function what is the minimum LFC threshold we want to use to consider a gene for ranking. For example, a LFC &gt; 2:</p> <p>code</p> <pre><code># score markers with LFC threshold of 2\nmarkers_lfc &lt;- scoreMarkers(sce,\n                           groups = sce$label,\n                           block = sce$SampleName,\n                           lfc = 2)\n\n# extract new results for cluster 11\nc11_markers_lfc2 &lt;- as.data.frame(markers_lfc[[\"11\"]])\n</code></pre> <ul> <li>Now, SNX10\u2019s rank dropped substantially:</li> </ul> <pre><code>c11_markers_lfc2[\"SNX10\",  c(\"rank.logFC.cohen\")]\n</code></pre>"},{"location":"episodes/8/#cell-type-labelling","title":"Cell Type Labelling","text":"<p>One of the main tasks we often want to perform is annotating our cells as known types of cells ocurring in our sampled tissue. This requires prior knowledge of cell transcriptomic states and therefore becomes easier if there are well-curated resources available. However, for less well-studied tissues these may not be available and so cell type annotation may rely on \u201cmanual annotation\u201d using a small set of genes with known cell-specific expression (e.g. from microscopy data, qPCR on cell-sorted samples, etc.).</p> <p>In this section we will do a very simple manual labelling of our clusters, based on known genes expressed in different blood cell types. However, there are more systematic methods for cell type annotation, in particular when prior information is available for those cells:</p> <ul> <li>The <code>SingleR</code> package uses previously labelled bulk or single-cell datasets to annotate a new dataset.</li> <li>The <code>AUCcell</code> package classifies cells into types based on user-provided lists of \u201csignature\u201d genes for each type. These lists can be generated from literature, or also be based on prior RNA-seq datasets.</li> <li>Another strategy is to perform a standard gene set enrichment analysis on the top marker genes for each cluster.</li> </ul>"},{"location":"episodes/8/#manual-annotation","title":"Manual Annotation","text":"<p>A lot is known about immune cell markers, in particular as many surface markers have been identified as useful for immunophenotyping.</p> <p>To help us in our annotation, we start by retrieving the top-ranked genes from each cluster into a list. We do this by looping through the list using the lapply() function and in each case picking the genes with rank &lt; 10 for Cohen\u2019s D statistic:</p> <p>code</p> <pre><code># loop through list of marker genes and extract top-ranked gene names\ntop_markers_all &lt;- lapply(markers, function(x){\n  x %&gt;% \n    as.data.frame() %&gt;% \n    filter(rank.logFC.cohen &lt; 10) %&gt;% \n    rownames()\n})\n\n# examining this list reveals several known markers of immune cells\ntop_markers_all\n</code></pre> <ul> <li>Let\u2019s visualise these markers\u2019 expression in our clusters:</li> </ul> <p><pre><code># cell type specific genes\nknown_genes &lt;- c(\n  \"HBA1\", # erythrocytes\n  \"CST3\", # monocytes\n  \"CD3E\", # T cells\n  \"NKG7\", # NK T cells\n  \"CD79A\",  # B cells\n  \"MS4A1\" # CD20 B cells\n  )\n\n# violin plot\nplotExpression(sce, x = \"label\", features = known_genes)\n</code></pre> </p> <p><pre><code># scaled heatmap of expression\nplotGroupedHeatmap(sce, \n                   features = known_genes,\n                   group = \"label\",\n                   block = \"SampleGroup\", \n                   scale = TRUE, center = TRUE, \n                   zlim = c(-3, 3))\n</code></pre> </p> <ul> <li> <p>Now that we have a more meaningful annotation for our clusters, let\u2019s add this to our <code>SingleCellExperiment</code> object. We will also add the original cluster ID in parenthesis to remind ourselves that this annotation was done based on the clusters.</p> </li> <li> <p>The cell labels are stored in the <code>SingleCellExperiment</code> object as a factor (a type of object in R to store categorical data), and so we can change the labels using the <code>levels()</code> function, like so:</p> </li> </ul> <p><pre><code># re-label the cells - original cluster in parenthesis\nlevels(colLabels(sce)) &lt;- c(\"B (c1)\", \"B (c2)\", \n                            \"B (c3)\", \"B (c4)\",\n                            \"CD20+ B (c5)\", \n                            \"T (c6)\", \"NK T (c7)\", \n                            \"Erythrocytes (c8)\", \"Erythrocytes (c9)\", \n                            \"Erythrocytes c(10)\",\n                            \"Monocytes (c11)\", \"B (c12)\")\n</code></pre> - Now, when we label our UMAP, we can see the new labels, which are more intutitive to interpret:</p> <p><pre><code># visualise UMAP with new labels\nplotReducedDim(sce, dimred = \"UMAP_corrected\", \n               colour_by = \"label\", text_by = \"label\")\n</code></pre> </p>"},{"location":"episodes/9.1/","title":"9. Differential expression analysis","text":"<p>When we have data for multiple conditions (e.g. control vs treatment, healthy vs diseased, wild-type vs mutant, etc.) and multiple biological replicates for each of them, we can investigate which genes are differentially expressed between conditions. This is similar to what is done in more conventional bulk RNA-seq analysis, but in this case we have the added benefit of being able to do our analysis focusing on particular cell clusters/types (which would not be possible to do in a bulk experiment, unless we had done cell-sorting before the sequencing).</p> <p>Differential analyses of multi-condition scRNA-seq experiments can be broadly split into two categories:</p> <ul> <li>differential expression (DE) tests for changes in expression between conditions for cells of the same \u2018type\u2019 that are present in both conditions.</li> <li>differential abundance (DA) tests for changes in the composition of cell types (or states, etc.) between conditions.</li> </ul> <p>In this section we will cover the first of these, i.e. how to do a differential expression analysis for a simple design with a single factor (variable) with two levels (conditions). In our case this corresponds to the comparison between cells from healthy (PBMMC) versus leukemia (ETV6-RUNX1) donors.</p> <p>There are three main steps for a bulk analysis:</p> <ul> <li>Creating the pseudo-bulk samples</li> <li>Filter low-count cells/samples</li> <li>Run the differential analysis</li> </ul> <p>Setup</p> <pre><code># load packages\nlibrary(scater)\nlibrary(scran)\nlibrary(batchelor)\nlibrary(bluster)\nlibrary(edgeR)\nlibrary(tidyverse)\n\n# load the SCE object\nsce &lt;- readRDS(\"R_objects/Caron_clustered.PBMMCandETV6RUNX1.rds\")\n\n# plot UMAP done on the batch-corrected data\nplotReducedDim(sce, dimred = \"UMAP_corrected\", \n               colour_by = \"label\", \n               text_by = \"label\")\n</code></pre>"},{"location":"episodes/9.1/#creating-pseudo-bulk-samples","title":"Creating pseudo-bulk samples","text":"<p>Pseudo-bulk samples consist of summing the counts across all the cells for a given sample and cell label combination. It is up to you to decide what the cell labels should consist of. In our case, we\u2019re using the Leiden clusters, which were further manually annotated according to cell types. But you may have defined these labels, for example, based on a more systematic cell type annotation using public atlases or reference gene panels</p> <p>To revise, here is how our sample + label combinations look like:</p> <p>Tabulate number of cells per label + sample combination</p> <pre><code>table(sce$label, sce$SampleName)\n</code></pre> <p>We can see that the contribution of each sample to the different labels (clusters) is quite unbalanced for some of them. This may be biologically correct, or it may prompt us to revise our batch correction step. For now, we will proceed with these data as they are.</p> <p>We use label and SampleName as the variables to aggregate by. We therefore will have a maximum of 7x17 (119) pseudo-samples. We will have less than this because, as we saw, there are some clusters with no cells from a particular sample.</p> <pre><code># sum counts across cells - by label and sample\nsummed &lt;- aggregateAcrossCells(sce, \n                               ids = colData(sce)[, c(\"label\", \"SampleName\")])\n\n# the output is a new SCE object with aggregated counts matrix\nsummed\n</code></pre>"},{"location":"episodes/9.1/#run-differential-expression","title":"Run differential expression","text":"<p>Now that we have pseudo-bulk samples, we can proceed to our differential expression analysis. This can be done using standard bulk RNA-seq R/Bioconductor packages, such as edgeR, DESeq2 or limma. In our case, we will use helper functions from scran, which, behind the scenes, use the edgeR package. If you are experienced in this sort of analysis, you could certainly use one of the other packages if you are more familiar with them.</p> <p>Before we run the actual differential analysis, we will filter pseudo-samples with low number of cells. Conveniently, the <code>aggregateAcrossCells()</code> function creates a new variable in our <code>colData()</code> slot with this information, so we can use it to do our filtering.</p> <p>code</p> <p><pre><code># \"ncells\" is added to our colData\ncolData(summed)[, c(\"SampleName\", \"ncells\")]\n</code></pre> <pre><code># use this to filter our pseudo-bulk object\nsummed &lt;- summed[, summed$ncells &gt;= 20]\n</code></pre></p> <p>We are now ready for our differential analysis. The scran package includes the function pseudoBulkDGE(), which conveniently loops through each label and performs the differential analysis between the two conditions.</p> <p>Here is the syntax for this step, with an explanation of the options to follow:</p> <pre><code># perform differential analysis for each label\n# this uses edgeR package behind the scenes.\nde_results &lt;- pseudoBulkDGE(summed, \n                            label = summed$label,\n                            design = ~ SampleGroup, \n                            coef = \"SampleGroupPBMMC\",\n                            condition = summed$SampleName)\n</code></pre> <p>There\u2019s a few options here we need to explain.</p> <p>First, the <code>design = ~ SampleGroup</code> option. This is R\u2019s formula syntax for defining linear models. In this case, we are indicating that we want to model the gene expression based on the \u201cSampleGroup\u201d variable of our <code>colData()</code>. This formula is converted to a so-called design matrix, which is internally used by the statistical machinery to fit the model to the data and perform a statistical test against a null hypothesis.</p> <p>It is useful to see what this model matrix looks like, to understand the next argument in this function (<code>coef = \"SampleGroupPBMMC\"</code>).</p> <p>code</p> <pre><code># the model matrix being used by edgeR\nhead(model.matrix(~ SampleGroup, data = colData(summed)))\n</code></pre> <p>This matrix contains an indicator variable (with 0\u2019s and 1\u2019s) indicating which sample belongs to the PBMMC group. If we want to test for differential expression between our \u201cETV6-RUNX1\u201d group and \u201cPBMMC\u201d, we need to specify the name of this indicator variable to the pseudoBulkDGE() function, as we did above.</p> <p>It may seem strange to have to do this, in this case, as we only have two groups. But if you had more than two groups (e.g. if we also had the \u201cHDD\u201d samples), then there would be more possible comparisons to do.</p> <p>Finally, we specified the option condition = summed$SampleName, which is used to automatically filter low-count genes.</p> <p>Looking at our output object, we can see that this is a list of DataFrame tables, containing the results of the analysis:</p> <p>code</p> <p><pre><code># the results come as a list for each cell label\nde_results\n</code></pre> <pre><code># extract one of the tables from the list\nb_c1_res &lt;- de_results[[1]]\n</code></pre></p> <ul> <li>These output tables contain metadata with the edgeR object that was used to fit the model, and we can use them for further quality-control analysis. For example, looking at the first of these comparisons for B cells present in our original cluster 1:</li> </ul> <pre><code># extract the edgeR object used for differential expression\nb_c1_dgelist &lt;- metadata(b_c1_res)$y\n\n# plot mean-CV relationship across genes\nplotBCV(b_c1_dgelist)\n</code></pre> <p></p> <p><pre><code># plot mean-difference plot to assess library size normalisation\n# we expect symmetrical distribution centered around zero\npar(mfrow=c(2,4))\nfor (i in seq_len(ncol(b_c1_dgelist))) {\n  plotMD(b_c1_dgelist, column=i)\n  abline(h = 0, col = \"salmon\", lwd = 2)\n}\n</code></pre> </p> <pre><code># plot MDS \nplotMDS(cpm(b_c1_dgelist, log = TRUE), \n        col = ifelse(b_c1_dgelist$samples$SampleGroup == \"PBMMC\", \"tomato\", \"steelblue\"))\n</code></pre> <ul> <li>The latter plot represents a projection of the data on a 2-dimensional plot using a dimensionality reduction method similar to PCA. This is useful to check if our samples separate in the way we may expect, given their different conditions. In this case we can see that the first dimension explains ~40% of the variance in the data and separates our samples according to their sample group, which would make sense biologically if their states are distinct between leukemia and healthy samples.</li> </ul> <p>We could further loop through all the results to produce a matrix of plots (this code is a little more advanced, but gives you an idea of how you could do this):</p> <p><pre><code># loop through all results\nlapply(de_results, function(current_result){\n  # extract the edgeR object from the metadata\n  current_result &lt;- metadata(current_result)$y\n\n  # make a colour scale\n  mds_cols &lt;- ifelse(current_result$samples$SampleGroup == \"PBMMC\", \"tomato\", \"steelblue\")\n\n  # identify the cell label this corresponds to\n  mds_title &lt;- unique(current_result$samples$label)\n\n  # make the plot\n  # note the `col` and `main` options are standard options in the base R plot()\n  plotMDS(cpm(current_result, log = TRUE), \n          col = mds_cols, main = mds_title)\n})\n</code></pre> </p>"},{"location":"episodes/9.1/#obtaining-de-genes","title":"Obtaining DE genes","text":"<p>After running the differential expression analysis, we can look at the differentially expressed genes for each cell type label. We can use the decideTestsPerLabel() function to achieve this, which allows us to define a false-discovery rate threshold (adjusted p-value), depending on our desired level of stringency.</p> <p>code</p> <p><pre><code># identify DEGs based on FDR threshold\nis_de &lt;- decideTestsPerLabel(de_results, threshold = 0.05)\n</code></pre> <pre><code># this outputs a large matrix\nis_de[1:10, 1:5]\n</code></pre></p> <p>The output is a large matrix (genes x label) containing the following values:</p> <ul> <li><code>-1</code> and <code>1</code>indicating the gene was down- or up-regulated in PBMMC samples, respectively</li> <li><code>0</code> indicating the gene was not differentially expressed</li> <li><code>NA</code> indicating there wasn\u2019t enough data to carry the test (e.g. all the replicates had zero counts in one of the groups) This matrix can be hard to interpret by itself, but we can summarise it as follows:</li> </ul> <p>code</p> <pre><code># summarise the results\nsummarizeTestsPerLabel(is_de)\n</code></pre> <p>We can see that there is a very large number of NA values in the results. This reflects the fact that many genes may not be sufficiently expressed in a given cell type to perform the statistical analysis, which should not surprise us given the sparsity often seen in single-cell data.</p> <p>However, we still get hundreds of genes differentially expressed in some of these clusters, suggesting differences between leukemia and healthy samples.</p> <p>Let\u2019s look at one of the top genes for one the B cell (cluster 1) label that we extracted out of our results list earlier.</p> <p>code</p> <p><pre><code># filter the results table for DEGs\nb_c1_res %&gt;% \n  as.data.frame() %&gt;% \n  arrange(FDR) %&gt;%\n  head()\n</code></pre> <pre><code># remove size factors from the object (otherwise plotting function complains)\n# and add normalised log counts to the object\nsizeFactors(summed) &lt;- NULL\nsummed &lt;- logNormCounts(summed)\n\n# visualise from our summed single cell object\nplotExpression(summed, \n               features = \"HTR1F\",\n               x = \"SampleName\", colour_by=\"SampleGroup\", \n               other_fields=\"label\") + \n  facet_wrap(~ label) +\n  scale_x_discrete(guide = guide_axis(angle = 45))\n</code></pre> </p> Exercise <p>We want to achieve the following:</p> <ul> <li>Rerun the differential expression analysis using the PRE-T and HHD samples.</li> <li>Determine which cluster has the most DEGs.</li> <li>Visualise the expression of one of the top genes for that cluster.</li> </ul> <pre><code># First load in the other two sample groups\nsce_PRET_HHD &lt;- readRDS(\"R_objects/Caron_clustered.PRETandHHD.rds\")\n</code></pre>"},{"location":"episodes/9.2/","title":"10. Differential Abundance","text":"<p>In the previous section we discussed how we can perform differential expression analysis using pseudo-bulk samples, when multiple biological replicates are available in a multi-condition experiment. Differential expression analysis addresses the question of whether a gene has a different average expression between the two groups being compared. However, another useful question to address is whether the cell composition also differs between conditions. We could imagine, for example, that natural killer cells are more abundant in leukemia samples than in healthy samples.</p> <p>This type of analysis is referred to as differential abundance analysis.</p> <p>Setup</p> <pre><code># load packages\nlibrary(BiocParallel)\nlibrary(scran)\nlibrary(scater)\nlibrary(miloR)\nlibrary(tidyverse)\nlibrary(patchwork)\n\n# load the SCE object\nsce &lt;- readRDS(\"R_objects/Caron_clustered.PBMMCandETV6RUNX1.rds\")\n\n# check the contents of the object\nsce\n\n# plot UMAP done on the batch-corrected data\nplotReducedDim(sce, dimred = \"UMAP_corrected\", \n               colour_by = \"label\", \n               text_by = \"label\")\n</code></pre>"},{"location":"episodes/9.2/#differential-abundance-between-conditions","title":"Differential abundance between conditions","text":"<p>code</p> <p>One method to perform DA analysis is to simply count how many cells occur in each label + condition combination and then test for differences in the counts between the two conditions.</p> <pre><code>table(sce$label, sce$SampleName)\n</code></pre> <ul> <li>As these are count data, statistical methods used in flow-cytometry have been adapted to test for differences in cell abundance from such a matrix of counts. </li> <li>However, this approach relies on a fixed set of clusters determined by us beforehand, which can be limiting in cases where the changes in abundance are more continuous (e.g. along a developmental trajectory, or where cell states are not completely discrete). To address this limitation, Dann et al. (2022) developed a method where cell abundance differences are tested along neighbourhoods of cells on a KNN graph. This means that the results aren\u2019t dependent on our clustering results, and are instead treated in a more \u201ccontinuous\u201d way.</li> </ul> <p>This method has been implemented by the authors in the R/Bioconductor package MiloR, which we cover in this section. Starting from a graph that faithfully recapitulates the biology of the cell population, the Milo analysis consists of 3 steps:</p> <ul> <li>Building a k-nearest neighbours (KNN) graph</li> <li>Sampling representative neighbourhoods in the graph (for computational efficiency)</li> <li>Testing for differential abundance of conditions in all neighbourhoods</li> <li>Accounting for multiple hypothesis testing using a weighted FDR procedure that accounts for the overlap of neighbourhoods</li> </ul> <p>The first step in the analysis is to turn our single cell object into a Milo object. This is very similar to the SingleCellExperiment object we\u2019ve been working with so far, but also includes information about the neighbourhood graphs that are built during the analysis.</p> <pre><code># create the Milo object can be simply converted from a SCE\nmilo &lt;- Milo(sce)\n\nmilo\n</code></pre> <ul> <li>Notice how there are now several slots with prefix `nhoods``, which we will explore as we go through the analysis.</li> </ul>"},{"location":"episodes/9.2/#construct-knn-graph","title":"Construct KNN graph","text":"<p>The first step in our analysis is to build a KNN graph from our cells. This is very similar to what we did earlier in the clustering session, except now the graph will be stored inside the object:</p> <pre><code># add KNN graph to Milo object\nmilo &lt;- buildGraph(milo, \n                   k = 60, \n                   d = 50, \n                   reduced.dim = \"corrected\", \n                   BPPARAM = MulticoreParam(4))\n</code></pre> <p>A couple of things to note about this:</p> <ul> <li><code>k</code> is the number of nearest neighbours to build the graph. This can be adjusted depending on how much of a fine resolution you want. If you use too high a number, you will end up loosing resolution as a higher diversity of cells will be connected in the graph. On the other hand, if you use too low a number, you may increase noise in the data and loose statistical power, as only very few cells will be connected to each other in a neighbourhood. The author\u2019s recommendation is to use a value of k as you did for clustering and UMAP visualisation - this is what we\u2019ve done in this case.</li> <li><code>d</code> is the number of dimensions from our dimensionality reduction matrix to use. In this case we\u2019re using the MNN-corrected matrix, which contains 50 dimensions, and we use all of them (50 is also the default, so we could have left this option out).</li> </ul> <p>The object now has a new object inside the graph slot, which a standard object type from the igraph package:</p> <pre><code># the graph is stored as a standard igraph object\ngraph(milo)\n</code></pre>"},{"location":"episodes/9.2/#define-neighbourhoods","title":"Define neighbourhoods","text":"<p>The next step in the analysis is to define cell neighbourhoods. This essentially consists of picking a focal cell and counting how many other cells it is connected to in the graph (and how many come from each group under comparison). However, if we did this for every single cell in the data, it could get computationally quite intractable. Instead, Milo implements a sampling step, where so-called \u201cindex cells\u201d are sampled from the larger graph, and those will be the neighbourhoods used in the DA analysis.</p> <p>This is done with the <code>makeNhodds()</code> function:</p> <p><pre><code># sample index cells to define neighbourhoods\nmilo &lt;- makeNhoods(milo, \n                   prop = 0.1, \n                   k = 60, \n                   d = 50, \n                   reduced_dims = \"corrected\")\n\n# check our object again\nmilo\n</code></pre> Some things to note:</p> <ul> <li>prop is the proportion of cells to sample (the authors advise 0.1 - 0.2).</li> <li><code>k</code> and <code>d</code> should be set the same as the k value used to build the original KNN graph. These values will be used for the graph-sampling algorithm used behind the scenes. We can also see that our Milo object now has the nhoods slots populated. In this case, it indicates that the sampling algorithm picked 1575 index cells to form neighbourhoods for DA analysis.</li> </ul> <p>One good QC metric to check at this stage is to create a histogram of cell counts per neighbourhood. Like we said earlier, when we set the value of k to define our KNN graph, we want to make sure the value is not too low, such that most neighbourhoods have very few cells, nor for it to be so high that we have very large (and presumably heterogenous) neighbourhoods.</p> <p>Conveniently, MiloR has a plotting function just for this purpose:</p> <p><pre><code># distribution of neighbourhood sizes\nplotNhoodSizeHist(milo) +\n  geom_vline(xintercept = 100, col = \"salmon\")\n</code></pre> </p> <p>The authors of Milo have stated several different parameters of deciding if your histogram is correct. Either \u2018peaking above 20\u2019, \u2018peaking between 50 and 100\u2019 or \u2018an average neighbourhood size over 5 x N_samples\u2019. Realistically, all of these statements give numbers in the same ballpark and so we can make a judgement on our data. In our case, we can see that our histogram peaks at ~100, suggesting a good neighbourhood size. If this was not the case, we could re-run the analysis from the start, making a KNN graph with a higher/lower <code>k</code> value.</p>"},{"location":"episodes/9.2/#counting-cells","title":"Counting cells","text":"<p>After defining our sample of neighbourhoods, the next step consists of counting how many cells there are in each neighbourhood for each sample replicate. In this step we need to define which column of our metadata we want to use to do the counting. We should count cells at the biological replicate leve, which in our case is stored in the SampleName column.</p> <p>code</p> <pre><code># count cells in each neighbourhood\nmilo &lt;- countCells(milo, \n                   meta.data = colData(milo),\n                   samples = \"SampleName\")\n\n# Milo now has a counts matrix\nhead(nhoodCounts(milo))\n</code></pre> <ul> <li>The dimensions of the counts matrix corresponds to the number of neighbourhoods (rows) and samples (columns), in our case a 1575 by 7 matrix.</li> </ul>"},{"location":"episodes/9.2/#neighbourhood-connectivity","title":"Neighbourhood connectivity","text":"<p>There is one more step that we need to do before we are ready to run our DA analysis. It consists of calculating the distances between each neighbourhood. As we said, the neighbourhoods on our graph may partially overlap, so when Milo corrects our p-values for multiple testing, it takes into account the spatial dependence of our tests. For example, neighbourhoods that are closer to each other may have similar p-values, and so we should avoid penalising them too much, otherwise we will sacrifice statistical power.</p> <p>code</p> <pre><code># calculate distances between neighbourhoods - for p-value correction\nmilo &lt;- calcNhoodDistance(milo, d = 50, reduced.dim = \"corrected\")\n</code></pre> <p>As before, the value of d (number of dimensions to consider from our MNN-corrected matrix) should be the same that was used for building our initial graph.</p>"},{"location":"episodes/9.2/#running-da-tests","title":"Running DA tests","text":"<p>Finally, we are ready to run the actual differential abundance step. Similarly to the pseudo-bulk appproach for differential expression, MiloR takes advantage of the edgeR package and its negative binomial linear model implementation. This provides a suitable statistical model to account for over-dispersed count data, as is common with these kind of datasets.</p> <p>First, we need to define a simple table with information about our samples - we will use this table to define our model formula (similarly to what we did in the differential expression step). In this case, we want to detect DA between our PBMMC and ETV6-RUNX1 sample groups, so we define a table based on those two groups. We could also include a batch column in this table, but to keep the demonstration simple we will skip this. We would normally do this if we know there is a batch effect that we want to account for it in DA testing.</p> <p>code</p> <pre><code># define a table for our model design\nsample_info &lt;- unique(colData(milo)[,c(\"SampleName\", \"SampleGroup\")])\nrownames(sample_info) &lt;- sample_info$SampleName\n\nsample_info\n</code></pre> <ul> <li>Now we can do the DA test, explicitly defining our experimental design. In this case as discussed we will test the difference between sample groups. The testNhoods function calculates a Fold-change and corrected P-value for each neighbourhood, which indicates whether there is significant differential abundance between sample groups.</li> </ul> <pre><code># run DA test\nda_results &lt;- testNhoods(milo, \n                         design = ~ SampleGroup, \n                         design.df = sample_info, \n                         reduced.dim = \"corrected\")\n\n# results are returned as a data.frame\nda_results %&gt;%\n  arrange(SpatialFDR) %&gt;%\n  head()\n</code></pre>"},{"location":"episodes/9.2/#inspecting-da-results","title":"Inspecting DA results","text":"<p>A good diagnostic plot to make after running our analysis is a histogram of p-values. We should expect a distribution with a peak close to 0 (corresponding to differentially abundant neighbourhoods) and tailing off towards 1. This blog article explains the different p-value histogram profiles you may see and what they can mean.</p> <p>code</p> <p><pre><code># p-value histogram\nggplot(da_results, aes(PValue)) + \n  geom_histogram(bins = 50)\n</code></pre> </p> <p>Next, we can get an overview of our results as a volcano plot, marking a significance threshold of 10% FDR:</p> <p><pre><code># volcano plot\n# each point in this plot corresponds to a neighbourhood (not a cell)\nggplot(da_results, aes(logFC, -log10(SpatialFDR))) + \n  geom_point(aes(colour = FDR &lt; 0.1)) +\n  geom_hline(yintercept = 1) \n</code></pre> </p> <p>As we can see, several neighbourhoods fall below our FDR threshold, indicating significant differential abundance of cells between PBMMC and ETV6-RUNX1 samples.</p> <p>There is an unsual discontinuity in our logFC axis, suggesting a sudden change in abundance in some of our neighbourhoods. We can get a better idea of the fold changes by visualising them as a graph for our neighbourhoods (rather than the original single-cell graph, which would be too big to display). We can then super-impose this graph on our original UMAP (or t-SNE), to compare with our original analysis.</p> <p>code</p> <p><pre><code># build neighbourhood graph embedding\nmilo &lt;- buildNhoodGraph(milo)\n</code></pre> <pre><code># our original UMAP with our previously annotated cell labels\numap_plot &lt;- plotReducedDim(milo, \n                            dimred = \"UMAP_corrected\", \n                            colour_by = \"label\", \n                            text_by = \"label\")\n\n# the neighbourhood map adjusted to match UMAP embedding\nnh_graph_plot &lt;- plotNhoodGraphDA(milo, \n                                  da_results, \n                                  layout = \"UMAP_corrected\",\n                                  alpha = 0.05)\n\n# the two plots together side-by-side\numap_plot + nh_graph_plot +\n  plot_layout(guides=\"collect\")\n</code></pre></p> <p>On the left we have our original UMAP, with cell/cluster annotations we did previously (by standard clustering and using known marker genes to manually annotate our cells). On the right we have the Milo neighbourhood graph, where each node represents a neighbourhood, coloured by the log fold-change in abundance between PBMMC and ETV6-RUNX1 samples (positive values represent higher abundance in ETV6-RUNX1, and vice-versa). We can see, for example, a cluster of cells with negative log fold changes around our large B cell cluster, which likely explains the discontinuity in values we saw earlier in our volcano plot.</p> <p>Although we have annotations for our cells, these annotations at the moment are not present in the differential abundance table:</p> <p>code</p> <p><pre><code>head(da_results)\n</code></pre> <pre><code># annotate our neighbourhood DA results with our cell labels\nda_results &lt;- annotateNhoods(milo, da_results, coldata_col = \"label\")\nhead(da_results)\n</code></pre></p> <p>The result includes the fraction of cells in the neighbourhood that shared that label. We can look at the distribution of this fraction as a quality check:</p> <pre><code># histogram of fraction of cells in the neighbourhood with the same label\nggplot(da_results, aes(label_fraction)) + \n  geom_histogram(bins = 50)\n</code></pre> <p></p> <p>We should expect the plot to be very biased towards 1, as is seen. This makes sense, since Milo\u2019s neighbourhoods should be very similar to our previously-defined clusters. After all, both our clustering and Milo used KNN graphs as the starting point, and we\u2019ve used the same settings for the k and d parameters in both steps of our analysis.</p> <p>Despite most neighbourhoods being homogenous, some seem to have mixed labels. We can highlight these in our results table:</p> <pre><code># add \"mixed\" label to neighbourhoods with less 70% consistency\nda_results$label &lt;- ifelse(da_results$label_fraction &lt; 0.7, \n                           \"Mixed\", \n                           da_results$label)\n\nhead(da_results)\n</code></pre> <p>Finally, we can visualise the distribution of DA fold changes in different labels.</p> <p><pre><code># distribution of logFC across neighbourhood labels\nplotDAbeeswarm(da_results, group.by = \"label\")\n</code></pre> </p>"}]}